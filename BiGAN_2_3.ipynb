{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiGAN_2.3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DjQ95L1gtq-m"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucabrombin/Unsupervised-anomaly-detection-in-Images-/blob/master/BiGAN_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wt8qIXvo2L1",
        "colab_type": "text"
      },
      "source": [
        "# First of all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngGL4TxLnAP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYYaLnSb2JrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from math import floor\n",
        "import numpy as np\n",
        "import time\n",
        "from functools import partial\n",
        "from random import random\n",
        "import os\n",
        "from keras.layers import Conv2D, Dense, AveragePooling2D, Activation, Cropping2D, Dropout, BatchNormalization\n",
        "from keras.layers import Reshape, UpSampling2D, Flatten, Input, add, Lambda, concatenate, LeakyReLU, multiply\n",
        "from keras.layers import GlobalAveragePooling2D, average\n",
        "from keras.models import model_from_json, Model\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "from typing import Tuple\n",
        "from enum import Enum\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iye-usQdoxQ6",
        "colab_type": "text"
      },
      "source": [
        "# Bidirectional GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gb9r380m1Ds",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "b4aa68b5-edcf-4370-f6e6-4f53fa07c816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from PIL import Image\n",
        "from math import floor\n",
        "import numpy as np\n",
        "import time\n",
        "from functools import partial\n",
        "from random import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from keras.models import Sequential, Model\n",
        "\n",
        "#from keras.layers import Input, Reshape, Dense, Dropout, MaxPooling2D, Conv2D, Flatten\n",
        "#from keras.layers import Conv2DTranspose, LeakyReLU\n",
        "\n",
        "#from keras.layers.core import Activation\n",
        "\n",
        "from keras.layers import Conv2D, Dense, AveragePooling2D, Activation, Cropping2D, Dropout, BatchNormalization\n",
        "from keras.layers import Reshape, UpSampling2D, Flatten, Input, add, Lambda, concatenate, LeakyReLU, multiply\n",
        "from keras.layers import GlobalAveragePooling2D, average\n",
        "from keras.models import model_from_json, Model\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
        "\n",
        "from sklearn.feature_extraction import image\n",
        "from sklearn.datasets import load_sample_image\n",
        "import cv2\n",
        "\n",
        "\n",
        "###GLOBAL VARIABLE###\n",
        "im_size = 128\n",
        "latent_size = 64\n",
        "BATCH_SIZE = 32\n",
        "directory = \"Object\"\n",
        "suff = 'png'\n",
        "cmode = 'RGB'\n",
        "channels = 3\n",
        "size_adjusted = False\n",
        "\n",
        "k_images = 3\n",
        "\n",
        "cha = 16\n",
        "object_name = \"Cable\"\n",
        "#####################\n",
        "\n",
        "def noise(n):\n",
        "    return np.random.normal(0.0, 1.0, size = [n, latent_size])\n",
        "\n",
        "\n",
        "class dataGenerator(object):\n",
        "\n",
        "    def __init__(self, loc, flip = False, suffix = 'png'):\n",
        "        self.flip = False\n",
        "        self.suffix = suffix\n",
        "        self.files = []\n",
        "        self.n = 1e10\n",
        "\n",
        "        print(\"Importing Images...\")\n",
        "        try:\n",
        "          os.mkdir(\"Results\")\n",
        "          os.mkdir(\"Models\")\n",
        "          os.mkdir(\"data\")\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "        try:\n",
        "            os.mkdir(\"/content/drive/My Drive/Colab Notebooks/BiGAN/Images/\"+str(object_name))\n",
        "            os.mkdir(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+str(object_name))\n",
        "        except:\n",
        "            pass\n",
        "            #self.load_from_npy(loc)\n",
        "            #return\n",
        "        DATASET_TRAIN_PATH = \"/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good\"\n",
        "        for dirpath, dirnames, filenames in os.walk(DATASET_TRAIN_PATH):\n",
        "            for filename in [f for f in filenames if f.endswith(\".\"+str('png'))]:\n",
        "                print('\\r' + str(len(self.files)), end = '\\r')\n",
        "                \n",
        "                fname = os.path.join(dirpath, filename)\n",
        "                print(fname)\n",
        "\n",
        "                temp = Image.open(fname).convert(cmode)\n",
        "                #im_size = 512\n",
        "                temp = temp.resize((im_size, im_size), Image.BILINEAR)\n",
        "                temp = np.array(temp, dtype='uint8')\n",
        "                #img = load_img(fname, target_size=(1024, 1024))\n",
        "                #img = np.array(img)\n",
        "\n",
        "                #print(img.shape)\n",
        "\n",
        "                #patches = image.extract_patches_2d(img, (256, 256), max_patches=4)\n",
        "                #print(patches.shape)\n",
        "\n",
        "                #blocks = np.array([img[i:i+256, j:j+256] for j in range(0,1024,256) for i in range(0,1024,256)])\n",
        "                \n",
        "                #for elem in blocks:\n",
        "                  #self.files.append(elem)\n",
        "                  #print(elem.shape)\n",
        "\n",
        "                self.files.append(temp)\n",
        "\n",
        "                #if self.flip:\n",
        "                #    self.files.append(np.flip(temp, 1))\n",
        "\n",
        "        self.files = np.array(self.files)\n",
        "\n",
        "        plt.imshow(self.files[0])\n",
        "        plt.show()\n",
        "\n",
        "        # define data preparation\n",
        "        #datagen = ImageDataGenerator(\n",
        "        #  rotation_range=20,\n",
        "        #  zoom_range=0.15,\n",
        "        #  width_shift_range=0.2,\n",
        "        #  height_shift_range=0.2,\n",
        "        #  shear_range=0.15,\n",
        "        #  horizontal_flip=True,\n",
        "        #  fill_mode=\"nearest\")\n",
        "\n",
        "        datagen = ImageDataGenerator(\n",
        "          rotation_range=0,\n",
        "          zoom_range=0,\n",
        "          width_shift_range=0,\n",
        "          height_shift_range=0,\n",
        "          #shear_range=0.15,\n",
        "          horizontal_flip=False,\n",
        "          fill_mode=\"nearest\")\n",
        "        \n",
        "        imageGen = datagen.flow(self.files, batch_size=1, save_to_dir=\"./temp\", save_prefix=\"image\", save_format=\"png\")\n",
        "\n",
        "        img = imageGen.next()\n",
        "        new_dataset = []\n",
        "        for i in range(0,10000):\n",
        "          \n",
        "          image = np.squeeze(img, axis = 0)\n",
        "          #plt.imshow(image.astype('uint8'))\n",
        "          #plt.show()\n",
        "\n",
        "          new_dataset.append(image)\n",
        "\n",
        "          img = imageGen.next()\n",
        "\n",
        "        self.files = np.array(new_dataset)\n",
        "          \n",
        "\n",
        "        #np.save(\"data/\" + loc + \"-npy-\" + str(im_size) + \"/data.npy\", self.files)\n",
        "\n",
        "        self.n = self.files.shape[0]\n",
        "\n",
        "        print(\"Found \" + str(self.n) + \" images in \" + loc + \".\")\n",
        "\n",
        "    def load_from_npy(self, loc):\n",
        "\n",
        "        print(\"Loading from .npy files.\")\n",
        "\n",
        "        self.files = np.load(\"data/\" + str(loc) + \"-npy-\" + str(im_size) + \"/data.npy\")\n",
        "\n",
        "        self.n = self.files.shape[0]\n",
        "\n",
        "\n",
        "    def get_batch(self, num):\n",
        "\n",
        "        idx = np.random.randint(0, self.n - 200, num)\n",
        "        out = []\n",
        "\n",
        "        for i in range(num):\n",
        "            out.append(self.files[idx[i]])\n",
        "\n",
        "        return np.array(out).astype('float32') / 255.0\n",
        "\n",
        "    def get_test_batch(self, num):\n",
        "\n",
        "        idx = np.random.randint(self.n - 200, self.n, num)\n",
        "        out = []\n",
        "\n",
        "        for i in range(num):\n",
        "            out.append(self.files[idx[i]])\n",
        "\n",
        "        return np.array(out).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "# Print iterations progress\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 50, fill = 'â–ˆ'):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print('\\r %s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total:\n",
        "        print()\n",
        "        print()\n",
        "\n",
        "def gradient_penalty_loss(y_true, y_pred, averaged_samples, weight):\n",
        "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "    gradients_sqr = K.square(gradients)\n",
        "    gradient_penalty = K.sum(gradients_sqr,\n",
        "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "\n",
        "    # (weight / 2) * ||grad||^2\n",
        "    # Penalize the gradient norm\n",
        "    return K.mean(gradient_penalty) * (weight / 2)\n",
        "\n",
        "def hinge_d(y_true, y_pred):\n",
        "    return K.mean(K.relu(1.0 - (y_true * y_pred)))\n",
        "\n",
        "def w_loss(y_true, y_pred):\n",
        "    return K.mean(y_true * y_pred)\n",
        "\n",
        "def g_block(inp, fil, u = True):\n",
        "\n",
        "    if u:\n",
        "        out = UpSampling2D(interpolation = 'bilinear')(inp)\n",
        "    else:\n",
        "        out = Activation('linear')(inp)\n",
        "\n",
        "    skip = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
        "\n",
        "    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
        "    out = LeakyReLU(0.2)(out)\n",
        "\n",
        "    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
        "    out = LeakyReLU(0.2)(out)\n",
        "\n",
        "    out = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
        "\n",
        "    out = add([out, skip])\n",
        "    out = LeakyReLU(0.2)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "def d_block(inp, fil, p = True):\n",
        "\n",
        "    skip = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(inp)\n",
        "\n",
        "    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(inp)\n",
        "    out = LeakyReLU(0.2)(out)\n",
        "\n",
        "    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
        "    out = LeakyReLU(0.2)(out)\n",
        "\n",
        "    out = Conv2D(fil, 1, padding = 'same', kernel_initializer = 'he_normal')(out)\n",
        "\n",
        "    out = add([out, skip])\n",
        "    out = LeakyReLU(0.2)(out)\n",
        "\n",
        "    if p:\n",
        "        out = AveragePooling2D()(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "class GAN(object):\n",
        "\n",
        "    def __init__(self, steps = 1, lr = 0.0001, decay = 0.00001):\n",
        "\n",
        "        #Models\n",
        "        self.D = None\n",
        "        self.E = None\n",
        "        self.G = None\n",
        "\n",
        "        self.GE = None\n",
        "        self.EE = None\n",
        "\n",
        "        self.DM = None\n",
        "        self.AM = None\n",
        "\n",
        "        #Config\n",
        "        self.LR = lr\n",
        "        self.steps = steps\n",
        "        self.beta = 0.999\n",
        "\n",
        "        #Init Models\n",
        "        self.discriminator()\n",
        "        self.generator()\n",
        "        self.encoder()\n",
        "\n",
        "        self.EE = model_from_json(self.E.to_json())\n",
        "        self.EE.set_weights(self.E.get_weights())\n",
        "\n",
        "        self.GE = model_from_json(self.G.to_json())\n",
        "        self.GE.set_weights(self.G.get_weights())\n",
        "\n",
        "    def discriminator(self):\n",
        "\n",
        "        if self.D:\n",
        "            return self.D\n",
        "\n",
        "        inp = Input(shape = [im_size, im_size, 3])\n",
        "        inpl = Input(shape = [latent_size])\n",
        "\n",
        "        #Latent input\n",
        "        l = Dense(512, kernel_initializer = 'he_normal')(inpl)\n",
        "        l = LeakyReLU(0.2)(l)\n",
        "        l = Dense(512, kernel_initializer = 'he_normal')(l)\n",
        "        l = LeakyReLU(0.2)(l)\n",
        "        l = Dense(512, kernel_initializer = 'he_normal')(l)\n",
        "        l = LeakyReLU(0.2)(l)\n",
        "\n",
        "        x = d_block(inp, 1 * cha)   #64\n",
        "        x = d_block(x, 2 * cha)   #32\n",
        "        x = d_block(x, 3 * cha)   #16\n",
        "        x = d_block(x, 4 * cha)  #8\n",
        "        x = d_block(x, 8 * cha)  #4\n",
        "        x = d_block(x, 16 * cha, p = False)  #4\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = concatenate([x, l])\n",
        "\n",
        "        x = Dense(16 * cha, kernel_initializer = 'he_normal')(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        x = Dense(1, kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "        self.D = Model(inputs = [inp, inpl], outputs = x)\n",
        "        self.D.summary()\n",
        "\n",
        "        return self.D\n",
        "\n",
        "    def generator(self):\n",
        "\n",
        "        if self.G:\n",
        "            return self.G\n",
        "\n",
        "        #Inputs\n",
        "        inp = Input(shape = [latent_size])\n",
        "\n",
        "        #Latent\n",
        "\n",
        "        #Actual Model\n",
        "        x = Dense(4*4*16*cha, kernel_initializer = 'he_normal')(inp)\n",
        "        x = Reshape([4, 4, 16*cha])(x)\n",
        "\n",
        "        x = g_block(x, 16 * cha, u = False)  #4\n",
        "        x = g_block(x, 8 * cha)  #8\n",
        "        x = g_block(x, 4 * cha)  #16\n",
        "        x = g_block(x, 3 * cha)   #32\n",
        "        x = g_block(x, 2 * cha)   #64\n",
        "        x = g_block(x, 1 * cha)   #128\n",
        "\n",
        "        x = Conv2D(filters = 3, kernel_size = 1, activation = 'sigmoid', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "        self.G = Model(inputs = inp, outputs = x)\n",
        "\n",
        "        return self.G\n",
        "\n",
        "    def encoder(self):\n",
        "\n",
        "        if self.E:\n",
        "            return self.E\n",
        "\n",
        "        inp = Input(shape = [im_size, im_size, 3])\n",
        "\n",
        "        x = d_block(inp, 1 * cha)   #64\n",
        "        x = d_block(x, 2 * cha)   #32\n",
        "        x = d_block(x, 3 * cha)   #16\n",
        "        x = d_block(x, 4 * cha)  #8\n",
        "        x = d_block(x, 8 * cha)  #4\n",
        "        x = d_block(x, 16 * cha, p = False)  #4\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        x = Dense(16 * cha, kernel_initializer = 'he_normal')(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        x = Dense(latent_size, kernel_initializer = 'he_normal', bias_initializer = 'zeros')(x)\n",
        "\n",
        "        self.E = Model(inputs = inp, outputs = x)\n",
        "        self.E.summary()\n",
        "\n",
        "        return self.E\n",
        "\n",
        "    def AdModel(self):\n",
        "\n",
        "        #D does not update\n",
        "        self.D.trainable = False\n",
        "        for layer in self.D.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        #G does update\n",
        "        self.G.trainable = True\n",
        "        for layer in self.G.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "        #E does update\n",
        "        self.E.trainable = True\n",
        "        for layer in self.E.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "        # Fake Latent / Real Image\n",
        "        ri = Input(shape = [im_size, im_size, 3])\n",
        "\n",
        "        er = self.E(ri)\n",
        "        dr = self.D([ri, er])\n",
        "\n",
        "        # Real Latent / Fake Image\n",
        "        gi = Input(shape = [latent_size])\n",
        "\n",
        "        gf = self.G(gi)\n",
        "        df = self.D([gf, gi])\n",
        "\n",
        "        self.AM = Model(inputs = [ri, gi], outputs = [dr, df])\n",
        "\n",
        "        self.AM.compile(optimizer = Adam(self.LR, beta_1 = 0, beta_2 = 0.099), loss = [w_loss, w_loss])\n",
        "\n",
        "        return self.AM\n",
        "\n",
        "    def DisModel(self):\n",
        "\n",
        "        #D does update\n",
        "        self.D.trainable = True\n",
        "        for layer in self.D.layers:\n",
        "            layer.trainable = True\n",
        "\n",
        "        #G does not update\n",
        "        self.G.trainable = False\n",
        "        for layer in self.G.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        #E does update\n",
        "        self.E.trainable = False\n",
        "        for layer in self.E.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # Fake Latent / Real Image\n",
        "        ri = Input(shape = [im_size, im_size, 3])\n",
        "\n",
        "        er = self.E(ri)\n",
        "        dr = self.D([ri, er])\n",
        "\n",
        "        # Real Latent / Fake Image\n",
        "        gi = Input(shape = [latent_size])\n",
        "\n",
        "        gf = self.G(gi)\n",
        "        df = self.D([gf, gi])\n",
        "\n",
        "        self.DM = Model(inputs = [ri, gi], outputs = [dr, df, df])\n",
        "\n",
        "        # Create partial of gradient penalty loss\n",
        "        # For r1, averaged_samples = ri\n",
        "        # For r2, averaged_samples = gf\n",
        "        # Weight of 10 typically works\n",
        "        partial_gp_loss = partial(gradient_penalty_loss, averaged_samples = [gf, gi], weight = 5)\n",
        "\n",
        "        #Compile With Corresponding Loss Functions\n",
        "        self.DM.compile(optimizer = Adam(self.LR, beta_1 = 0, beta_2 = 0.909), loss=[hinge_d, hinge_d, partial_gp_loss])\n",
        "\n",
        "        return self.DM\n",
        "\n",
        "    def EMA(self):\n",
        "\n",
        "        start = time.clock()\n",
        "\n",
        "        for i in range(len(self.G.layers)):\n",
        "            up_weight = self.G.layers[i].get_weights()\n",
        "            old_weight = self.GE.layers[i].get_weights()\n",
        "            new_weight = []\n",
        "            for j in range(len(up_weight)):\n",
        "                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n",
        "            self.GE.layers[i].set_weights(new_weight)\n",
        "\n",
        "        for i in range(len(self.E.layers)):\n",
        "            up_weight = self.E.layers[i].get_weights()\n",
        "            old_weight = self.EE.layers[i].get_weights()\n",
        "            new_weight = []\n",
        "            for j in range(len(up_weight)):\n",
        "                new_weight.append(old_weight[j] * self.beta + (1-self.beta) * up_weight[j])\n",
        "            self.EE.layers[i].set_weights(new_weight)\n",
        "\n",
        "        #print(\"Moved Average. \" + str(time.clock() - start) + \"s\")\n",
        "\n",
        "    def MAinit(self):\n",
        "        self.EE.set_weights(self.E.get_weights())\n",
        "        self.GE.set_weights(self.G.get_weights())\n",
        "\n",
        "class BiGAN(object):\n",
        "\n",
        "    def __init__(self, steps = 1, lr = 0.0001, decay = 0.00001, silent = True):\n",
        "\n",
        "        self.GAN = GAN(steps = steps, lr = lr, decay = decay)\n",
        "        self.DisModel = self.GAN.DisModel()\n",
        "        self.AdModel = self.GAN.AdModel()\n",
        "\n",
        "        # LOAD THE LAST MODEL SAVED TO CONTINUE THE TRAINING FROM \"step\" ITERATION \n",
        "        self.load(1)\n",
        "\n",
        "        self.lastblip = time.clock()\n",
        "\n",
        "        self.noise_level = 0\n",
        "\n",
        "        self.im = dataGenerator(directory, suffix = suff, flip = True)\n",
        "\n",
        "        self.silent = silent\n",
        "\n",
        "        #Train Generator to be in the middle, not all the way at real. Apparently works better??\n",
        "        self.ones = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
        "        self.zeros = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
        "        self.nones = -self.ones\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        #Train Alternating\n",
        "        a = self.train_dis()\n",
        "        b = self.train_gen()\n",
        "\n",
        "        if self.GAN.steps % 10 == 0:\n",
        "            self.GAN.EMA()\n",
        "\n",
        "        if self.GAN.steps == 20000:\n",
        "            self.GAN.MAinit()\n",
        "\n",
        "\n",
        "        #Print info\n",
        "        if self.GAN.steps % 100 == 0 and not self.silent:\n",
        "            print(\"\\n\\nRound \" + str(self.GAN.steps) + \":\")\n",
        "            print(\"D: \" + str(a))\n",
        "            print(\"G: \" + str(b))\n",
        "            s = round((time.clock() - self.lastblip), 4)\n",
        "            steps_per_second = 100 / s\n",
        "            steps_per_minute = steps_per_second * 60\n",
        "            steps_per_hour = steps_per_minute * 60\n",
        "            print(\"Steps/Second: \" + str(round(steps_per_second, 2)))\n",
        "            print(\"Steps/Hour: \" + str(round(steps_per_hour)))\n",
        "            min1k = floor(1000/steps_per_minute)\n",
        "            sec1k = floor(1000/steps_per_second) % 60\n",
        "            print(\"1k Steps: \" + str(min1k) + \":\" + str(sec1k))\n",
        "            self.lastblip = time.clock()\n",
        "            steps_left = 200000 - self.GAN.steps + 1e-7\n",
        "            hours_left = steps_left // steps_per_hour\n",
        "            minutes_left = (steps_left // steps_per_minute) % 60\n",
        "\n",
        "            print(\"Til Completion: \" + str(int(hours_left)) + \"h\" + str(int(minutes_left)) + \"m\")\n",
        "            print()\n",
        "\n",
        "            #Save Model\n",
        "            if self.GAN.steps % 1000 == 0:\n",
        "                self.save(floor(self.GAN.steps / 1000))\n",
        "\n",
        "            if self.GAN.steps % 1000 == 0 or (self.GAN.steps % 100 == 0 and self.GAN.steps < 1000):\n",
        "                self.evaluate(floor(self.GAN.steps / 1000))\n",
        "\n",
        "\n",
        "        printProgressBar(self.GAN.steps % 100, 99, decimals = 0)\n",
        "\n",
        "        self.GAN.steps = self.GAN.steps + 1\n",
        "\n",
        "    def train_dis(self):\n",
        "\n",
        "        #Get Data\n",
        "        train_data = [self.im.get_batch(BATCH_SIZE), noise(BATCH_SIZE)]\n",
        "\n",
        "        #Train\n",
        "        d_loss = self.DisModel.train_on_batch(train_data, [self.ones, self.nones, self.ones])\n",
        "\n",
        "        return d_loss\n",
        "\n",
        "    def train_gen(self):\n",
        "\n",
        "        #Train\n",
        "        train_data = [self.im.get_batch(BATCH_SIZE), noise(BATCH_SIZE)]\n",
        "\n",
        "        g_loss = self.AdModel.train_on_batch(train_data, [self.ones, self.nones])\n",
        "\n",
        "        return g_loss\n",
        "\n",
        "    def evaluate(self, num = 0):\n",
        "\n",
        "        n1 = noise(32)\n",
        "\n",
        "        generated_images = self.GAN.G.predict(n1, batch_size = BATCH_SIZE)\n",
        "\n",
        "        real_images = self.im.get_test_batch(16)\n",
        "        latent_codes = self.GAN.E.predict(real_images, batch_size = BATCH_SIZE)\n",
        "        reconstructed_images = self.GAN.G.predict(latent_codes, batch_size = BATCH_SIZE)\n",
        "\n",
        "        print(\"E Mean: \" + str(np.mean(latent_codes)))\n",
        "        print(\"E Std: \" + str(np.std(latent_codes)))\n",
        "        print(\"E Std Featurewise: \" + str(np.mean(np.std(latent_codes, axis = 0))))\n",
        "        print()\n",
        "\n",
        "        r = []\n",
        "\n",
        "        for i in range(0, 32, 8):\n",
        "            r.append(np.concatenate(generated_images[i:i+8], axis = 1))\n",
        "\n",
        "        hline = np.zeros([16, 8 * im_size, 3])\n",
        "        r.append(hline)\n",
        "\n",
        "        for i in range(0, 16, 8):\n",
        "            r.append(np.concatenate(real_images[i:i+8], axis = 1))\n",
        "            r.append(np.concatenate(reconstructed_images[i:i+8], axis = 1))\n",
        "\n",
        "        c1 = np.concatenate(r, axis = 0)\n",
        "\n",
        "        x = Image.fromarray(np.uint8(c1*255))\n",
        "\n",
        "        x.save(\"/content/drive/My Drive/Colab Notebooks/BiGAN/Images/\"+object_name+\"/i\"+str(num)+\".png\")\n",
        "\n",
        "        # Moving Average\n",
        "\n",
        "        n1 = noise(32)\n",
        "\n",
        "        generated_images = self.GAN.GE.predict(n1, batch_size = BATCH_SIZE)\n",
        "\n",
        "        latent_codes = self.GAN.EE.predict(real_images, batch_size = BATCH_SIZE)\n",
        "        reconstructed_images = self.GAN.GE.predict(latent_codes, batch_size = BATCH_SIZE)\n",
        "\n",
        "        r = []\n",
        "\n",
        "        for i in range(0, 32, 8):\n",
        "            r.append(np.concatenate(generated_images[i:i+8], axis = 1))\n",
        "\n",
        "        hline = np.zeros([16, 8 * im_size, 3])\n",
        "        r.append(hline)\n",
        "\n",
        "        for i in range(0, 16, 8):\n",
        "            r.append(np.concatenate(real_images[i:i+8], axis = 1))\n",
        "            r.append(np.concatenate(reconstructed_images[i:i+8], axis = 1))\n",
        "\n",
        "        c1 = np.concatenate(r, axis = 0)\n",
        "\n",
        "        x = Image.fromarray(np.uint8(c1*255))\n",
        "\n",
        "        x.save(\"/content/drive/My Drive/Colab Notebooks/BiGAN/Images/\"+object_name+\"/i\"+str(num)+\"-ema.png\")\n",
        "\n",
        "\n",
        "    def prepareSamples(self, cnum = 0, num = 1000): #8x8 images, bottom row is constant\n",
        "\n",
        "        try:\n",
        "            os.mkdir(\"Results/Samples-c\" + str(cnum))\n",
        "        except:\n",
        "            x = 0\n",
        "\n",
        "        im = self.im.get_class(cnum)\n",
        "        e = self.GAN.E.predict(im, batch_size = BATCH_SIZE * k_images)\n",
        "\n",
        "        mean = np.mean(e, axis = 0)\n",
        "        std = np.std(e, axis = 0)\n",
        "\n",
        "        n = noise(num)\n",
        "        nc = nClass(num, mean, std)\n",
        "\n",
        "        im = self.GAN.G.predict([n, nc], batch_size = BATCH_SIZE)\n",
        "\n",
        "        for i in range(im.shape[0]):\n",
        "\n",
        "            x = Image.fromarray(np.uint8(im[i]*255), mode = 'RGB')\n",
        "\n",
        "            x.save(\"Results/Samples-c\" + str(cnum) + \"/im (\"+str(i+1)+\").png\")\n",
        "\n",
        "    def saveModel(self, model, name, num):\n",
        "        json = model.to_json()\n",
        "        with open(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+object_name+\"/\"+name+\".json\", \"w\") as json_file:\n",
        "            json_file.write(json)\n",
        "\n",
        "        model.save_weights(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+object_name+\"/\"+name+\"_\"+str(num)+\".h5\")\n",
        "        #model.save(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n",
        "\n",
        "    def loadModel(self, name, num):\n",
        "\n",
        "        file = open(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+object_name+\"/\"+name+\".json\", 'r')\n",
        "        json = file.read()\n",
        "        file.close()\n",
        "\n",
        "        mod = model_from_json(json)\n",
        "        mod.load_weights(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+object_name+\"/\"+name+\"_\"+str(num)+\".h5\")\n",
        "\n",
        "        return mod\n",
        "\n",
        "    def save(self, num): #Save JSON and Weights into /Models/\n",
        "        self.saveModel(self.GAN.G, \"gen\", num)\n",
        "        self.saveModel(self.GAN.D, \"dis\", num)\n",
        "        self.saveModel(self.GAN.E, \"enc\", num)\n",
        "\n",
        "        self.saveModel(self.GAN.GE, \"genMA\", num)\n",
        "        self.saveModel(self.GAN.EE, \"encMA\", num)\n",
        "\n",
        "\n",
        "    def load(self, num): #Load JSON and Weights from /Models/\n",
        "        steps1 = self.GAN.steps\n",
        "\n",
        "        #Load Models\n",
        "        self.GAN.G = self.loadModel(\"gen\", num)\n",
        "        self.GAN.D = self.loadModel(\"dis\", num)\n",
        "        self.GAN.E = self.loadModel(\"enc\", num)\n",
        "\n",
        "        self.GAN.GE = self.loadModel(\"genMA\", num)\n",
        "        self.GAN.EE = self.loadModel(\"encMA\", num)\n",
        "\n",
        "        self.GAN.steps = steps1\n",
        "\n",
        "        self.DisModel = self.GAN.DisModel()\n",
        "        self.AdModel = self.GAN.AdModel()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #np.random.seed(1)\n",
        "    model = BiGAN(lr = 0.0001, silent = False)\n",
        "    #model.evaluate(0)\n",
        "\n",
        "    while model.GAN.steps <= 600000:\n",
        "      model.train()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 128, 128, 16) 448         input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 128, 128, 16) 2320        leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, 128, 128, 16) 0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 128, 128, 16) 272         leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 128, 128, 16) 64          input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 128, 128, 16) 0           conv2d_77[0][0]                  \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, 128, 128, 16) 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 64, 64, 16)   0           leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 64, 64, 32)   4640        average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 64, 64, 32)   9248        leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, 64, 64, 32)   0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 64, 64, 32)   1056        leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 64, 64, 32)   544         average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 64, 64, 32)   0           conv2d_81[0][0]                  \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, 64, 64, 32)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 32, 32, 32)   0           leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 32, 32, 48)   13872       average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)      (None, 32, 32, 48)   0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 48)   20784       leaky_re_lu_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)      (None, 32, 32, 48)   0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 48)   2352        leaky_re_lu_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 32, 32, 48)   1584        average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 32, 32, 48)   0           conv2d_85[0][0]                  \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)      (None, 32, 32, 48)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 16, 16, 48)   0           leaky_re_lu_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 16, 16, 64)   27712       average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, 16, 16, 64)   0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 16, 16, 64)   36928       leaky_re_lu_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_73 (LeakyReLU)      (None, 16, 16, 64)   0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 16, 16, 64)   4160        leaky_re_lu_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 16, 16, 64)   3136        average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 64)   0           conv2d_89[0][0]                  \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_74 (LeakyReLU)      (None, 16, 16, 64)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 8, 8, 64)     0           leaky_re_lu_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 128)    73856       average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_75 (LeakyReLU)      (None, 8, 8, 128)    0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 128)    147584      leaky_re_lu_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_76 (LeakyReLU)      (None, 8, 8, 128)    0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 128)    16512       leaky_re_lu_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 128)    8320        average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 8, 8, 128)    0           conv2d_93[0][0]                  \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_77 (LeakyReLU)      (None, 8, 8, 128)    0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 4, 4, 128)    0           leaky_re_lu_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 4, 4, 256)    295168      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_78 (LeakyReLU)      (None, 4, 4, 256)    0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 64)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 4, 4, 256)    590080      leaky_re_lu_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 512)          33280       input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_79 (LeakyReLU)      (None, 4, 4, 256)    0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, 512)          0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 4, 4, 256)    65792       leaky_re_lu_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 4, 4, 256)    33024       average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 512)          262656      leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 4, 4, 256)    0           conv2d_97[0][0]                  \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, 512)          0           dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_80 (LeakyReLU)      (None, 4, 4, 256)    0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 512)          262656      leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 4096)         0           leaky_re_lu_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, 512)          0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4608)         0           flatten_3[0][0]                  \n",
            "                                                                 leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 256)          1179904     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_81 (LeakyReLU)      (None, 256)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            257         leaky_re_lu_81[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 3,098,209\n",
            "Trainable params: 3,098,209\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 128, 128, 16) 448         input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_100 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 128, 128, 16) 2320        leaky_re_lu_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_101 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 128, 128, 16) 272         leaky_re_lu_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 128, 128, 16) 64          input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 128, 128, 16) 0           conv2d_126[0][0]                 \n",
            "                                                                 conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_102 (LeakyReLU)     (None, 128, 128, 16) 0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 64, 64, 16)   0           leaky_re_lu_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 64, 64, 32)   4640        average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_103 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 64, 64, 32)   9248        leaky_re_lu_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_104 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 64, 64, 32)   1056        leaky_re_lu_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 64, 64, 32)   544         average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 64, 64, 32)   0           conv2d_130[0][0]                 \n",
            "                                                                 conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_105 (LeakyReLU)     (None, 64, 64, 32)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 32, 32, 32)   0           leaky_re_lu_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 48)   13872       average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_106 (LeakyReLU)     (None, 32, 32, 48)   0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 48)   20784       leaky_re_lu_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_107 (LeakyReLU)     (None, 32, 32, 48)   0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 48)   2352        leaky_re_lu_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 48)   1584        average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 32, 32, 48)   0           conv2d_134[0][0]                 \n",
            "                                                                 conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_108 (LeakyReLU)     (None, 32, 32, 48)   0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 16, 16, 48)   0           leaky_re_lu_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 64)   27712       average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_109 (LeakyReLU)     (None, 16, 16, 64)   0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 16, 16, 64)   36928       leaky_re_lu_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_110 (LeakyReLU)     (None, 16, 16, 64)   0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 16, 16, 64)   4160        leaky_re_lu_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 16, 16, 64)   3136        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 16, 16, 64)   0           conv2d_138[0][0]                 \n",
            "                                                                 conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_111 (LeakyReLU)     (None, 16, 16, 64)   0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 8, 8, 64)     0           leaky_re_lu_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 128)    73856       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_112 (LeakyReLU)     (None, 8, 8, 128)    0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 128)    147584      leaky_re_lu_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_113 (LeakyReLU)     (None, 8, 8, 128)    0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 128)    16512       leaky_re_lu_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 128)    8320        average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 8, 8, 128)    0           conv2d_142[0][0]                 \n",
            "                                                                 conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_114 (LeakyReLU)     (None, 8, 8, 128)    0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 4, 4, 128)    0           leaky_re_lu_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 4, 4, 256)    295168      average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_115 (LeakyReLU)     (None, 4, 4, 256)    0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 4, 4, 256)    590080      leaky_re_lu_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_116 (LeakyReLU)     (None, 4, 4, 256)    0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 4, 4, 256)    65792       leaky_re_lu_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 4, 4, 256)    33024       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 4, 4, 256)    0           conv2d_146[0][0]                 \n",
            "                                                                 conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_117 (LeakyReLU)     (None, 4, 4, 256)    0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 4096)         0           leaky_re_lu_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 256)          1048832     flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_118 (LeakyReLU)     (None, 256)          0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 64)           16448       leaky_re_lu_118[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 2,424,736\n",
            "Trainable params: 2,424,736\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Importing Images...\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/132.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/094.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/015.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/079.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/049.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/030.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/032.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/086.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/110.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/199.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/161.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/146.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/035.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/172.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/043.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/025.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/153.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/003.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/078.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/150.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/206.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/028.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/010.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/090.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/178.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/005.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/102.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/128.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/075.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/149.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/056.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/167.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/180.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/208.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/057.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/217.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/070.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/222.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/152.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/051.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/185.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/033.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/072.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/181.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/124.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/135.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/036.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/054.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/145.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/009.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/061.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/187.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/017.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/216.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/156.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/087.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/123.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/080.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/085.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/157.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/223.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/067.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/029.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/198.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/092.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/081.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/134.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/011.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/031.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/205.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/175.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/022.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/084.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/210.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/039.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/160.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/184.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/012.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/095.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/089.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/143.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/163.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/125.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/211.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/099.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/048.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/214.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/019.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/116.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/108.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/058.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/133.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/142.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/127.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/212.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/000.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/093.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/189.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/006.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/168.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/215.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/107.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/164.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/014.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/066.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/069.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/024.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/007.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/137.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/139.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/062.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/113.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/173.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/096.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/159.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/170.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/098.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/065.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/207.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/071.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/213.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/162.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/204.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/195.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/130.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/193.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/151.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/155.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/191.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/131.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/097.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/053.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/147.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/166.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/200.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/083.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/074.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/101.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/188.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/138.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/040.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/220.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/148.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/111.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/041.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/038.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/052.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/202.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/119.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/026.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/194.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/021.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/186.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/042.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/209.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/050.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/176.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/068.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/047.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/045.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/158.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/183.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/118.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/192.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/115.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/201.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/016.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/154.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/064.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/055.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/219.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/136.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/190.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/114.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/002.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/105.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/182.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/018.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/197.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/174.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/044.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/020.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/126.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/091.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/023.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/144.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/103.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/077.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/100.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/082.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/034.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/218.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/112.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/059.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/171.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/141.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/106.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/179.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/117.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/060.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/165.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/073.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/037.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/121.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/203.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/104.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/001.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/013.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/196.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/063.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/027.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/008.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/140.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/076.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/088.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/046.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/129.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/177.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/109.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/004.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/122.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/120.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/221.png\n",
            "/content/drive/My Drive/Colab Notebooks/test_AD_1/cable/train/good/169.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOZpNoEGDbY5mE2jQYJuj2QQaNNjm+A9dijV0oRmNPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images in Object.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  |--------------------------------------------------| 1% \r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 100:\n",
            "D: [1.7828937, 1.2445593, 0.39493358, 0.14340079]\n",
            "G: [0.4725128, 0.02969468, 0.44281814]\n",
            "Steps/Second: 0.45\n",
            "Steps/Hour: 1632\n",
            "1k Steps: 36:46\n",
            "Til Completion: 122h30m\n",
            "\n",
            "E Mean: -0.08335906\n",
            "E Std: 0.99042284\n",
            "E Std Featurewise: 0.432794\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 200:\n",
            "D: [1.8579518, 1.1416624, 0.5687211, 0.14756837]\n",
            "G: [0.55168796, -0.20313175, 0.7548197]\n",
            "Steps/Second: 2.95\n",
            "Steps/Hour: 10606\n",
            "1k Steps: 5:39\n",
            "Til Completion: 18h50m\n",
            "\n",
            "E Mean: 0.025026737\n",
            "E Std: 1.1824555\n",
            "E Std Featurewise: 0.43862462\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 300:\n",
            "D: [2.4936836, 2.367593, 0.0, 0.12609056]\n",
            "G: [0.51627105, 1.1368679, -0.6205968]\n",
            "Steps/Second: 3.71\n",
            "Steps/Hour: 13348\n",
            "1k Steps: 4:29\n",
            "Til Completion: 14h57m\n",
            "\n",
            "E Mean: -0.019212462\n",
            "E Std: 0.9636858\n",
            "E Std Featurewise: 0.6160768\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 400:\n",
            "D: [2.0940146, 1.9750272, 0.0, 0.1189874]\n",
            "G: [0.4146893, 1.0943934, -0.67970407]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13684\n",
            "1k Steps: 4:23\n",
            "Til Completion: 14h35m\n",
            "\n",
            "E Mean: -0.1398848\n",
            "E Std: 1.0617234\n",
            "E Std Featurewise: 0.7456357\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 500:\n",
            "D: [1.9666378, 1.086714, 0.6624135, 0.21751028]\n",
            "G: [0.6684748, 0.37380177, 0.29467306]\n",
            "Steps/Second: 3.74\n",
            "Steps/Hour: 13480\n",
            "1k Steps: 4:27\n",
            "Til Completion: 14h48m\n",
            "\n",
            "E Mean: -0.009423236\n",
            "E Std: 1.0075073\n",
            "E Std Featurewise: 0.7230679\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 600:\n",
            "D: [1.7486573, 0.8297258, 0.7040055, 0.21492615]\n",
            "G: [0.7653678, 0.2334019, 0.5319659]\n",
            "Steps/Second: 3.7\n",
            "Steps/Hour: 13331\n",
            "1k Steps: 4:30\n",
            "Til Completion: 14h57m\n",
            "\n",
            "E Mean: -0.036495805\n",
            "E Std: 0.91650295\n",
            "E Std Featurewise: 0.75174963\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 700:\n",
            "D: [1.8495187, 0.12073601, 1.5123479, 0.21643475]\n",
            "G: [0.5789864, -0.37465036, 0.95363677]\n",
            "Steps/Second: 3.74\n",
            "Steps/Hour: 13453\n",
            "1k Steps: 4:27\n",
            "Til Completion: 14h48m\n",
            "\n",
            "E Mean: -0.03313119\n",
            "E Std: 1.1031913\n",
            "E Std Featurewise: 0.8656498\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 800:\n",
            "D: [1.6236118, 0.7402527, 0.6430641, 0.24029505]\n",
            "G: [0.7164938, 0.2234761, 0.4930177]\n",
            "Steps/Second: 3.75\n",
            "Steps/Hour: 13516\n",
            "1k Steps: 4:26\n",
            "Til Completion: 14h44m\n",
            "\n",
            "E Mean: 0.009046101\n",
            "E Std: 0.9034011\n",
            "E Std Featurewise: 0.7995589\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 900:\n",
            "D: [2.2237942, 2.1116471, 0.0, 0.112147115]\n",
            "G: [0.54260564, 0.91891634, -0.37631068]\n",
            "Steps/Second: 3.72\n",
            "Steps/Hour: 13392\n",
            "1k Steps: 4:28\n",
            "Til Completion: 14h52m\n",
            "\n",
            "E Mean: -0.0039608274\n",
            "E Std: 1.2371588\n",
            "E Std Featurewise: 0.89842916\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1000:\n",
            "D: [1.4167118, 0.4939415, 0.6684607, 0.2543097]\n",
            "G: [0.8253634, 0.021293752, 0.80406964]\n",
            "Steps/Second: 3.71\n",
            "Steps/Hour: 13361\n",
            "1k Steps: 4:29\n",
            "Til Completion: 14h53m\n",
            "\n",
            "E Mean: -0.14300087\n",
            "E Std: 1.076776\n",
            "E Std Featurewise: 0.8888304\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1100:\n",
            "D: [1.5930481, 0.71568316, 0.61626244, 0.2611025]\n",
            "G: [0.9193211, 0.42621964, 0.49310148]\n",
            "Steps/Second: 2.11\n",
            "Steps/Hour: 7609\n",
            "1k Steps: 7:53\n",
            "Til Completion: 26h8m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1200:\n",
            "D: [1.4950135, 0.6130651, 0.6258415, 0.2561069]\n",
            "G: [0.7890371, 0.2930558, 0.49598128]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13926\n",
            "1k Steps: 4:18\n",
            "Til Completion: 14h16m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1300:\n",
            "D: [1.461302, 0.70116645, 0.49187922, 0.2682565]\n",
            "G: [1.0699341, 0.38801855, 0.6819155]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13977\n",
            "1k Steps: 4:17\n",
            "Til Completion: 14h12m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1400:\n",
            "D: [1.3989179, 0.6307181, 0.5251955, 0.24300434]\n",
            "G: [1.0008479, 0.089865215, 0.9109827]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14053\n",
            "1k Steps: 4:16\n",
            "Til Completion: 14h7m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1500:\n",
            "D: [1.322994, 0.46559018, 0.6435563, 0.21384746]\n",
            "G: [1.0826803, 0.29305542, 0.7896249]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14170\n",
            "1k Steps: 4:14\n",
            "Til Completion: 14h0m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1600:\n",
            "D: [1.8201019, 0.116731636, 1.3479848, 0.3553854]\n",
            "G: [0.9690337, -0.5343524, 1.5033861]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14078\n",
            "1k Steps: 4:15\n",
            "Til Completion: 14h5m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1700:\n",
            "D: [1.5322686, 0.7936482, 0.4771703, 0.26145014]\n",
            "G: [1.1174142, 0.44369632, 0.673718]\n",
            "Steps/Second: 3.81\n",
            "Steps/Hour: 13703\n",
            "1k Steps: 4:22\n",
            "Til Completion: 14h28m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1800:\n",
            "D: [1.2689518, 0.394642, 0.5622396, 0.3120702]\n",
            "G: [1.1806629, 0.41486433, 0.7657985]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13779\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 1900:\n",
            "D: [1.3382769, 0.61045617, 0.48183382, 0.2459869]\n",
            "G: [1.1506915, 0.54719853, 0.603493]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13809\n",
            "1k Steps: 4:20\n",
            "Til Completion: 14h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2000:\n",
            "D: [1.1256137, 0.5292115, 0.36053473, 0.23586743]\n",
            "G: [1.1792916, 0.7143998, 0.46489182]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13667\n",
            "1k Steps: 4:23\n",
            "Til Completion: 14h29m\n",
            "\n",
            "E Mean: -0.07603466\n",
            "E Std: 0.94426954\n",
            "E Std Featurewise: 0.61570597\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2100:\n",
            "D: [1.1418878, 0.75946295, 0.0900771, 0.2923477]\n",
            "G: [1.4442778, 1.0677062, 0.3765716]\n",
            "Steps/Second: 3.65\n",
            "Steps/Hour: 13144\n",
            "1k Steps: 4:33\n",
            "Til Completion: 15h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2200:\n",
            "D: [1.2912465, 1.0182798, 0.064293884, 0.20867291]\n",
            "G: [1.3272085, 1.2813616, 0.045846958]\n",
            "Steps/Second: 3.79\n",
            "Steps/Hour: 13651\n",
            "1k Steps: 4:23\n",
            "Til Completion: 14h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2300:\n",
            "D: [1.3118905, 0.95724046, 0.11231141, 0.24233861]\n",
            "G: [1.4453951, 1.1108611, 0.33453408]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13798\n",
            "1k Steps: 4:20\n",
            "Til Completion: 14h19m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2400:\n",
            "D: [1.7477831, 1.5814183, 0.0, 0.16636476]\n",
            "G: [1.3892541, 1.0241972, 0.36505693]\n",
            "Steps/Second: 3.79\n",
            "Steps/Hour: 13631\n",
            "1k Steps: 4:24\n",
            "Til Completion: 14h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2500:\n",
            "D: [1.2215235, 0.118368156, 0.7704359, 0.3327195]\n",
            "G: [1.4773849, 0.38999832, 1.0873866]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14037\n",
            "1k Steps: 4:16\n",
            "Til Completion: 14h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2600:\n",
            "D: [1.3328059, 1.015443, 0.050028197, 0.26733473]\n",
            "G: [1.4463809, 1.1366172, 0.3097636]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13843\n",
            "1k Steps: 4:20\n",
            "Til Completion: 14h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2700:\n",
            "D: [1.613853, 0.005436156, 1.2776737, 0.330743]\n",
            "G: [1.0320312, 0.034186676, 0.99784446]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 14010\n",
            "1k Steps: 4:16\n",
            "Til Completion: 14h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2800:\n",
            "D: [1.0576982, 0.7393507, 0.09597491, 0.22237264]\n",
            "G: [1.4575137, 0.904896, 0.55261767]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13878\n",
            "1k Steps: 4:19\n",
            "Til Completion: 14h12m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 2900:\n",
            "D: [0.80111897, 0.46699572, 0.057581056, 0.27654216]\n",
            "G: [1.540575, 1.3236926, 0.2168825]\n",
            "Steps/Second: 3.74\n",
            "Steps/Hour: 13474\n",
            "1k Steps: 4:27\n",
            "Til Completion: 14h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3000:\n",
            "D: [0.7574846, 0.20162685, 0.24037716, 0.3154806]\n",
            "G: [1.6604669, 0.82197094, 0.83849597]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13773\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h18m\n",
            "\n",
            "E Mean: 0.0023255134\n",
            "E Std: 1.1393083\n",
            "E Std Featurewise: 0.7742375\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3100:\n",
            "D: [1.0454799, 0.04161469, 0.6775218, 0.32634333]\n",
            "G: [1.5905964, 0.24311602, 1.3474804]\n",
            "Steps/Second: 3.6\n",
            "Steps/Hour: 12953\n",
            "1k Steps: 4:37\n",
            "Til Completion: 15h12m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3200:\n",
            "D: [0.92684984, 0.20942153, 0.37619, 0.34123832]\n",
            "G: [1.747959, 0.5371603, 1.2107987]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13743\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h19m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3300:\n",
            "D: [0.9777365, 0.08877075, 0.55023724, 0.3387285]\n",
            "G: [1.8003734, 0.40163252, 1.3987409]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13779\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h16m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3400:\n",
            "D: [0.9919755, 0.033122454, 0.6303247, 0.32852829]\n",
            "G: [1.732002, 0.47580594, 1.256196]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13827\n",
            "1k Steps: 4:20\n",
            "Til Completion: 14h13m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3500:\n",
            "D: [0.9624264, 0.012663774, 0.5981223, 0.35164034]\n",
            "G: [1.7392397, 0.3636778, 1.375562]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13737\n",
            "1k Steps: 4:22\n",
            "Til Completion: 14h18m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3600:\n",
            "D: [0.7676426, 0.2923072, 0.14546363, 0.32987174]\n",
            "G: [1.9894485, 0.9432869, 1.0461617]\n",
            "Steps/Second: 3.76\n",
            "Steps/Hour: 13542\n",
            "1k Steps: 4:25\n",
            "Til Completion: 14h30m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3700:\n",
            "D: [0.9245246, 0.021607801, 0.50283074, 0.40008605]\n",
            "G: [1.8043166, 0.3833325, 1.4209841]\n",
            "Steps/Second: 3.78\n",
            "Steps/Hour: 13613\n",
            "1k Steps: 4:24\n",
            "Til Completion: 14h25m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3800:\n",
            "D: [0.95802045, 0.0, 0.5997678, 0.35825267]\n",
            "G: [1.6375059, 0.18238567, 1.4551202]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13916\n",
            "1k Steps: 4:18\n",
            "Til Completion: 14h5m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 3900:\n",
            "D: [0.9935872, 0.04282257, 0.5619742, 0.38879043]\n",
            "G: [1.8745224, 0.38958865, 1.4849339]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13750\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4000:\n",
            "D: [0.6976295, 0.42741024, 0.01455264, 0.2556666]\n",
            "G: [1.963704, 1.4738603, 0.4898437]\n",
            "Steps/Second: 3.81\n",
            "Steps/Hour: 13731\n",
            "1k Steps: 4:22\n",
            "Til Completion: 14h16m\n",
            "\n",
            "E Mean: -0.07957809\n",
            "E Std: 1.3331903\n",
            "E Std Featurewise: 0.95981896\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4100:\n",
            "D: [0.9980341, 0.82500947, 0.003731845, 0.16929284]\n",
            "G: [1.8565919, 1.1841704, 0.67242163]\n",
            "Steps/Second: 3.6\n",
            "Steps/Hour: 12953\n",
            "1k Steps: 4:37\n",
            "Til Completion: 15h7m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4200:\n",
            "D: [0.80771387, 0.57680947, 0.027085429, 0.20381895]\n",
            "G: [2.1430774, 1.5070639, 0.6360136]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13761\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h13m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4300:\n",
            "D: [0.9750679, 0.007758606, 0.6083701, 0.35893917]\n",
            "G: [1.7231908, 0.3074083, 1.4157825]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13928\n",
            "1k Steps: 4:18\n",
            "Til Completion: 14h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4400:\n",
            "D: [0.7466056, 0.47542006, 0.032563332, 0.2386222]\n",
            "G: [2.2064214, 1.4831501, 0.72327113]\n",
            "Steps/Second: 3.73\n",
            "Steps/Hour: 13431\n",
            "1k Steps: 4:28\n",
            "Til Completion: 14h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4500:\n",
            "D: [0.49039555, 0.17271945, 0.082244635, 0.23543146]\n",
            "G: [2.4117684, 1.3245592, 1.0872092]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13904\n",
            "1k Steps: 4:18\n",
            "Til Completion: 14h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4600:\n",
            "D: [0.98778963, 0.034385443, 0.57596433, 0.37743986]\n",
            "G: [1.9936563, 0.6000205, 1.3936357]\n",
            "Steps/Second: 3.79\n",
            "Steps/Hour: 13644\n",
            "1k Steps: 4:23\n",
            "Til Completion: 14h19m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4700:\n",
            "D: [1.0429516, 0.010243889, 0.63850474, 0.39420292]\n",
            "G: [1.837139, 0.4142188, 1.4229202]\n",
            "Steps/Second: 3.78\n",
            "Steps/Hour: 13617\n",
            "1k Steps: 4:24\n",
            "Til Completion: 14h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4800:\n",
            "D: [0.48947868, 0.002607666, 0.18320495, 0.30366606]\n",
            "G: [1.9648666, 0.59399974, 1.3708669]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13696\n",
            "1k Steps: 4:22\n",
            "Til Completion: 14h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 4900:\n",
            "D: [0.77427995, 0.60764366, 0.0, 0.16663627]\n",
            "G: [2.5498066, 1.6702187, 0.87958777]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13926\n",
            "1k Steps: 4:18\n",
            "Til Completion: 14h0m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5000:\n",
            "D: [0.72703743, 0.0092456285, 0.31097072, 0.40682107]\n",
            "G: [2.1832278, 0.5863411, 1.5968866]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13783\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h8m\n",
            "\n",
            "E Mean: -0.13171428\n",
            "E Std: 0.99207485\n",
            "E Std Featurewise: 0.8100289\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5100:\n",
            "D: [0.85706097, 0.69638425, 0.00040172786, 0.16027498]\n",
            "G: [2.0751169, 1.3571088, 0.7180081]\n",
            "Steps/Second: 3.62\n",
            "Steps/Hour: 13035\n",
            "1k Steps: 4:36\n",
            "Til Completion: 14h57m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5200:\n",
            "D: [0.51112336, 0.31729823, 0.0140212495, 0.17980388]\n",
            "G: [2.5296469, 1.6246204, 0.90502656]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13875\n",
            "1k Steps: 4:19\n",
            "Til Completion: 14h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5300:\n",
            "D: [0.44984075, 0.2685094, 0.006872151, 0.17445922]\n",
            "G: [2.3713756, 1.483543, 0.88783264]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13693\n",
            "1k Steps: 4:22\n",
            "Til Completion: 14h13m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5400:\n",
            "D: [0.44761723, 0.06260123, 0.12537444, 0.25964156]\n",
            "G: [2.1904154, 0.924925, 1.2654903]\n",
            "Steps/Second: 3.78\n",
            "Steps/Hour: 13622\n",
            "1k Steps: 4:24\n",
            "Til Completion: 14h17m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5500:\n",
            "D: [0.67204094, 0.5070195, 0.00036176294, 0.16465965]\n",
            "G: [2.3843355, 1.8067977, 0.5775378]\n",
            "Steps/Second: 3.79\n",
            "Steps/Hour: 13637\n",
            "1k Steps: 4:23\n",
            "Til Completion: 14h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5600:\n",
            "D: [0.51377124, 0.39309293, 0.0, 0.12067831]\n",
            "G: [2.373232, 1.5232673, 0.8499645]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13769\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h7m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5700:\n",
            "D: [0.7473028, 0.035522062, 0.3605228, 0.3512579]\n",
            "G: [2.2424765, 0.8673195, 1.3751569]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13768\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h6m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5800:\n",
            "D: [0.5817679, 0.1964758, 0.13209791, 0.25319424]\n",
            "G: [2.405465, 1.4136751, 0.9917898]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13874\n",
            "1k Steps: 4:19\n",
            "Til Completion: 13h59m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 5900:\n",
            "D: [0.4818012, 0.25669357, 0.046002716, 0.17910492]\n",
            "G: [2.5457683, 1.7561005, 0.7896678]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13820\n",
            "1k Steps: 4:20\n",
            "Til Completion: 14h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6000:\n",
            "D: [0.41554427, 0.27697626, 0.01284132, 0.12572668]\n",
            "G: [2.6235318, 1.6939914, 0.9295404]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13843\n",
            "1k Steps: 4:20\n",
            "Til Completion: 14h0m\n",
            "\n",
            "E Mean: 0.017841956\n",
            "E Std: 1.0254622\n",
            "E Std Featurewise: 0.8613496\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6100:\n",
            "D: [0.52112013, 0.42320427, 0.0, 0.097915865]\n",
            "G: [2.4576702, 1.7866242, 0.6710459]\n",
            "Steps/Second: 3.59\n",
            "Steps/Hour: 12937\n",
            "1k Steps: 4:38\n",
            "Til Completion: 14h59m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6200:\n",
            "D: [0.67914385, 0.5754714, 0.0039925277, 0.09967989]\n",
            "G: [2.7793927, 1.7732716, 1.006121]\n",
            "Steps/Second: 3.76\n",
            "Steps/Hour: 13551\n",
            "1k Steps: 4:25\n",
            "Til Completion: 14h18m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6300:\n",
            "D: [0.37992775, 0.2226924, 0.008249061, 0.14898631]\n",
            "G: [2.4934926, 1.6406164, 0.85287607]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13741\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h5m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6400:\n",
            "D: [0.5520965, 0.01488978, 0.21959618, 0.31761053]\n",
            "G: [2.2383208, 0.8427174, 1.3956034]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13665\n",
            "1k Steps: 4:23\n",
            "Til Completion: 14h10m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6500:\n",
            "D: [0.6219455, 0.48098755, 0.008852186, 0.13210577]\n",
            "G: [2.316049, 1.6241751, 0.691874]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13781\n",
            "1k Steps: 4:21\n",
            "Til Completion: 14h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6600:\n",
            "D: [0.3152442, 0.16072139, 0.0150800105, 0.13944282]\n",
            "G: [2.8086562, 1.7992435, 1.0094128]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13874\n",
            "1k Steps: 4:19\n",
            "Til Completion: 13h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6700:\n",
            "D: [0.42092562, 0.16616039, 0.0837767, 0.17098852]\n",
            "G: [2.4335644, 1.2008338, 1.2327306]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14050\n",
            "1k Steps: 4:16\n",
            "Til Completion: 13h45m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6800:\n",
            "D: [0.43038774, 0.06664471, 0.13274539, 0.23099765]\n",
            "G: [2.2895815, 1.042007, 1.2475746]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14141\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h39m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 6900:\n",
            "D: [0.7661612, 0.6948335, 0.0, 0.07132768]\n",
            "G: [2.5165489, 1.8935399, 0.623009]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14137\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h39m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7000:\n",
            "D: [0.6227001, 0.54379755, 0.0, 0.07890251]\n",
            "G: [2.4800653, 1.7601062, 0.7199591]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13850\n",
            "1k Steps: 4:19\n",
            "Til Completion: 13h56m\n",
            "\n",
            "E Mean: -0.032539614\n",
            "E Std: 1.2155578\n",
            "E Std Featurewise: 1.1114202\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7100:\n",
            "D: [0.31377274, 0.068423174, 0.03134603, 0.21400353]\n",
            "G: [2.6470447, 1.6482866, 0.99875796]\n",
            "Steps/Second: 3.62\n",
            "Steps/Hour: 13032\n",
            "1k Steps: 4:36\n",
            "Til Completion: 14h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7200:\n",
            "D: [0.29218513, 0.18969655, 0.010293266, 0.09219531]\n",
            "G: [2.4118755, 1.6240563, 0.78781915]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13933\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7300:\n",
            "D: [0.3899548, 0.024824873, 0.110380605, 0.25474933]\n",
            "G: [2.4367664, 1.17029, 1.2664764]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14208\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7400:\n",
            "D: [0.62257737, 0.55993307, 0.0, 0.06264432]\n",
            "G: [2.66885, 1.7410631, 0.9277867]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14216\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7500:\n",
            "D: [0.7182859, 0.04930777, 0.33083594, 0.3381422]\n",
            "G: [1.6598498, 0.29063892, 1.3692108]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14194\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7600:\n",
            "D: [0.36632115, 0.0, 0.127737, 0.23858416]\n",
            "G: [2.1710277, 0.7912352, 1.3797923]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14342\n",
            "1k Steps: 4:11\n",
            "Til Completion: 13h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7700:\n",
            "D: [0.22766635, 0.11306137, 0.005825691, 0.10877929]\n",
            "G: [2.6249352, 1.4387631, 1.186172]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14174\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h34m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7800:\n",
            "D: [0.37023157, 0.08356413, 0.08611563, 0.20055181]\n",
            "G: [2.6552982, 1.3091714, 1.3461268]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14141\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h35m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 7900:\n",
            "D: [0.24969716, 0.049152926, 0.05201316, 0.14853108]\n",
            "G: [2.5887845, 1.4496393, 1.1391451]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14189\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8000:\n",
            "D: [0.34381276, 0.21959414, 0.02450595, 0.099712685]\n",
            "G: [2.8683648, 1.8611577, 1.0072073]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14298\n",
            "1k Steps: 4:11\n",
            "Til Completion: 13h25m\n",
            "\n",
            "E Mean: 0.034290694\n",
            "E Std: 1.2065245\n",
            "E Std Featurewise: 1.1015458\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8100:\n",
            "D: [0.32389426, 0.21438499, 0.007808266, 0.10170101]\n",
            "G: [2.6337268, 1.8830563, 0.75067055]\n",
            "Steps/Second: 3.72\n",
            "Steps/Hour: 13398\n",
            "1k Steps: 4:28\n",
            "Til Completion: 14h19m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8200:\n",
            "D: [0.23728724, 0.08008067, 0.03353639, 0.123670176]\n",
            "G: [2.6691778, 1.4220809, 1.2470969]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14331\n",
            "1k Steps: 4:11\n",
            "Til Completion: 13h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8300:\n",
            "D: [0.3830784, 0.035703663, 0.13893482, 0.2084399]\n",
            "G: [2.6794739, 1.4165655, 1.2629082]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14164\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8400:\n",
            "D: [0.43413156, 0.3742301, 0.0, 0.059901483]\n",
            "G: [2.7383533, 1.8366768, 0.9016765]\n",
            "Steps/Second: 4.02\n",
            "Steps/Hour: 14459\n",
            "1k Steps: 4:8\n",
            "Til Completion: 13h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8500:\n",
            "D: [0.25737798, 0.15848355, 0.00021870062, 0.09867571]\n",
            "G: [2.6921597, 1.8542261, 0.83793354]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14155\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h31m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8600:\n",
            "D: [0.5289142, 0.088455886, 0.20496526, 0.23549303]\n",
            "G: [2.3524885, 1.180042, 1.1724465]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14139\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8700:\n",
            "D: [0.30651367, 0.076752156, 0.06457916, 0.16518234]\n",
            "G: [2.5685165, 1.4325575, 1.135959]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13972\n",
            "1k Steps: 4:17\n",
            "Til Completion: 13h41m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8800:\n",
            "D: [0.40058392, 0.21240264, 0.059050176, 0.12913111]\n",
            "G: [2.7615848, 1.7828015, 0.97878337]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13933\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h43m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 8900:\n",
            "D: [0.30221933, 0.02156848, 0.09355287, 0.18709797]\n",
            "G: [2.5736623, 1.4060826, 1.1675797]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13918\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h43m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9000:\n",
            "D: [0.2465001, 0.051512316, 0.05737356, 0.13761422]\n",
            "G: [2.5085588, 1.3184674, 1.1900914]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13929\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h42m\n",
            "\n",
            "E Mean: 0.040226117\n",
            "E Std: 1.142154\n",
            "E Std Featurewise: 1.069844\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9100:\n",
            "D: [0.45645583, 0.01569028, 0.17795062, 0.26281494]\n",
            "G: [2.091138, 0.7549627, 1.3361753]\n",
            "Steps/Second: 3.68\n",
            "Steps/Hour: 13250\n",
            "1k Steps: 4:31\n",
            "Til Completion: 14h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9200:\n",
            "D: [0.3505583, 0.15791927, 0.08631395, 0.10632508]\n",
            "G: [2.36828, 1.3866851, 0.9815948]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14234\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9300:\n",
            "D: [0.4311568, 0.34738517, 0.00910042, 0.07467124]\n",
            "G: [2.7128673, 1.8093796, 0.9034878]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14120\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h30m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9400:\n",
            "D: [0.3736798, 0.24400112, 0.027572831, 0.102105826]\n",
            "G: [2.6611311, 1.7482892, 0.912842]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13948\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h39m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9500:\n",
            "D: [0.25523198, 0.069498986, 0.046822358, 0.13891064]\n",
            "G: [2.2231472, 1.095762, 1.1273851]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14075\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9600:\n",
            "D: [0.4929338, 0.05282067, 0.19032013, 0.24979301]\n",
            "G: [2.2283444, 0.95394397, 1.2744005]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 13997\n",
            "1k Steps: 4:17\n",
            "Til Completion: 13h36m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9700:\n",
            "D: [0.62374187, 0.0020780228, 0.27739644, 0.34426737]\n",
            "G: [1.9571598, 0.6138524, 1.3433074]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13839\n",
            "1k Steps: 4:20\n",
            "Til Completion: 13h45m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9800:\n",
            "D: [0.45653754, 0.42226806, 0.00044820085, 0.033821274]\n",
            "G: [2.8140478, 1.9238927, 0.8901552]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14055\n",
            "1k Steps: 4:16\n",
            "Til Completion: 13h31m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 9900:\n",
            "D: [0.2475903, 0.04228721, 0.04812959, 0.15717351]\n",
            "G: [2.4056747, 1.1726577, 1.233017]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13976\n",
            "1k Steps: 4:17\n",
            "Til Completion: 13h36m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10000:\n",
            "D: [0.59817785, 0.035492867, 0.26843983, 0.29424515]\n",
            "G: [2.3929935, 1.1012584, 1.2917352]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14128\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h26m\n",
            "\n",
            "E Mean: 0.09106581\n",
            "E Std: 1.1841404\n",
            "E Std Featurewise: 1.0959485\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10100:\n",
            "D: [0.26957634, 0.044799373, 0.08341922, 0.14135775]\n",
            "G: [2.6512828, 1.4852146, 1.1660683]\n",
            "Steps/Second: 3.64\n",
            "Steps/Hour: 13103\n",
            "1k Steps: 4:34\n",
            "Til Completion: 14h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10200:\n",
            "D: [0.35634398, 0.20184503, 0.04743702, 0.10706193]\n",
            "G: [2.7802083, 1.6742861, 1.1059222]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14065\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10300:\n",
            "D: [0.33792052, 0.15777777, 0.052211355, 0.12793139]\n",
            "G: [2.6838992, 1.4979277, 1.1859715]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13943\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h36m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10400:\n",
            "D: [0.3233402, 0.03339824, 0.06669642, 0.22324555]\n",
            "G: [2.5606499, 1.3263255, 1.2343242]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14077\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h28m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10500:\n",
            "D: [0.45534343, 0.018225541, 0.16656621, 0.27055168]\n",
            "G: [1.8290257, 0.63103247, 1.1979933]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14126\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10600:\n",
            "D: [0.33674008, 0.20319417, 0.025706463, 0.10783944]\n",
            "G: [2.48762, 1.5494046, 0.93821555]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14113\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h25m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10700:\n",
            "D: [0.416122, 0.04522056, 0.15616883, 0.21473259]\n",
            "G: [2.1156087, 0.90820885, 1.2073998]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14122\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10800:\n",
            "D: [0.381676, 0.19618587, 0.0410717, 0.14441842]\n",
            "G: [2.6378388, 1.5458829, 1.0919558]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14131\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 10900:\n",
            "D: [0.3254673, 0.2476309, 0.013773315, 0.064063065]\n",
            "G: [2.714538, 1.7059871, 1.0085509]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14150\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h21m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11000:\n",
            "D: [0.73440206, 0.003714731, 0.36648178, 0.36420554]\n",
            "G: [1.623783, 0.29342887, 1.3303541]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14171\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h20m\n",
            "\n",
            "E Mean: -0.049725085\n",
            "E Std: 1.1460477\n",
            "E Std Featurewise: 1.0625942\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11100:\n",
            "D: [0.43826133, 0.13013335, 0.107115135, 0.20101286]\n",
            "G: [2.7021196, 1.6699799, 1.0321397]\n",
            "Steps/Second: 3.68\n",
            "Steps/Hour: 13244\n",
            "1k Steps: 4:31\n",
            "Til Completion: 14h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11200:\n",
            "D: [0.4134351, 0.2980702, 0.015078744, 0.10028617]\n",
            "G: [2.7431536, 2.1074767, 0.63567686]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14379\n",
            "1k Steps: 4:10\n",
            "Til Completion: 13h7m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11300:\n",
            "D: [0.52852786, 0.11574043, 0.14861459, 0.26417288]\n",
            "G: [2.1159043, 0.956452, 1.1594524]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14425\n",
            "1k Steps: 4:9\n",
            "Til Completion: 13h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11400:\n",
            "D: [0.32279602, 0.2973027, 0.0, 0.025493318]\n",
            "G: [2.865191, 1.8653268, 0.9998641]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14192\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h17m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11500:\n",
            "D: [0.27875155, 0.08948945, 0.06181004, 0.12745208]\n",
            "G: [2.6814299, 1.4871087, 1.194321]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14182\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h17m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11600:\n",
            "D: [0.31101936, 0.06786552, 0.07486667, 0.16828719]\n",
            "G: [2.4552734, 1.340713, 1.1145604]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14126\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11700:\n",
            "D: [0.24681965, 0.029565299, 0.059058398, 0.15819594]\n",
            "G: [2.468766, 1.2505174, 1.2182486]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14293\n",
            "1k Steps: 4:11\n",
            "Til Completion: 13h10m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11800:\n",
            "D: [0.28349477, 0.031562325, 0.06654376, 0.18538868]\n",
            "G: [2.3824205, 1.1970494, 1.1853712]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13911\n",
            "1k Steps: 4:18\n",
            "Til Completion: 13h31m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 11900:\n",
            "D: [0.24595228, 0.04185643, 0.06936531, 0.13473055]\n",
            "G: [2.5706847, 1.4027758, 1.1679089]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13884\n",
            "1k Steps: 4:19\n",
            "Til Completion: 13h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12000:\n",
            "D: [0.38571957, 0.03199003, 0.16272321, 0.19100633]\n",
            "G: [2.60463, 1.448418, 1.1562119]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13897\n",
            "1k Steps: 4:19\n",
            "Til Completion: 13h31m\n",
            "\n",
            "E Mean: -0.08830558\n",
            "E Std: 1.2081834\n",
            "E Std Featurewise: 1.1006427\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12100:\n",
            "D: [0.2882576, 0.115424305, 0.05873194, 0.114101335]\n",
            "G: [2.74215, 1.639781, 1.1023691]\n",
            "Steps/Second: 3.69\n",
            "Steps/Hour: 13288\n",
            "1k Steps: 4:30\n",
            "Til Completion: 14h8m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12200:\n",
            "D: [0.53099984, 0.08269013, 0.15396218, 0.29434752]\n",
            "G: [1.774993, 0.45522207, 1.3197709]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14069\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12300:\n",
            "D: [0.23863196, 0.1064333, 0.035884365, 0.09631429]\n",
            "G: [2.6447177, 1.6045306, 1.0401872]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 14018\n",
            "1k Steps: 4:16\n",
            "Til Completion: 13h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12400:\n",
            "D: [0.3813965, 0.16320966, 0.07334429, 0.14484255]\n",
            "G: [2.687728, 1.5579928, 1.129735]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14387\n",
            "1k Steps: 4:10\n",
            "Til Completion: 13h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12500:\n",
            "D: [0.29429528, 0.20869277, 0.020612579, 0.06498993]\n",
            "G: [2.4919484, 1.552309, 0.93963933]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14092\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h18m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12600:\n",
            "D: [0.31285065, 0.10634937, 0.054982252, 0.15151905]\n",
            "G: [2.5269854, 1.4702184, 1.056767]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14306\n",
            "1k Steps: 4:11\n",
            "Til Completion: 13h5m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12700:\n",
            "D: [0.45918512, 0.19545378, 0.10311452, 0.16061682]\n",
            "G: [2.4858017, 1.430444, 1.0553577]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14178\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h12m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12800:\n",
            "D: [0.4691651, 0.0672428, 0.15316291, 0.24875939]\n",
            "G: [2.2226973, 1.0706121, 1.1520851]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14379\n",
            "1k Steps: 4:10\n",
            "Til Completion: 13h1m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 12900:\n",
            "D: [0.5778361, 0.5582391, 0.0, 0.019596979]\n",
            "G: [3.1087093, 2.2827983, 0.825911]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14372\n",
            "1k Steps: 4:10\n",
            "Til Completion: 13h1m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13000:\n",
            "D: [0.31081626, 0.22761288, 0.027725248, 0.05547812]\n",
            "G: [2.5463734, 1.4681594, 1.0782138]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14272\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h6m\n",
            "\n",
            "E Mean: 0.03454393\n",
            "E Std: 1.1786443\n",
            "E Std Featurewise: 1.0917501\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13100:\n",
            "D: [0.39029646, 0.12407931, 0.12140572, 0.14481144]\n",
            "G: [2.6040916, 1.4799042, 1.1241874]\n",
            "Steps/Second: 3.76\n",
            "Steps/Hour: 13531\n",
            "1k Steps: 4:26\n",
            "Til Completion: 13h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13200:\n",
            "D: [0.3872549, 0.06689925, 0.14124022, 0.1791154]\n",
            "G: [2.4495375, 1.3336678, 1.1158698]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14269\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h5m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13300:\n",
            "D: [0.29923737, 0.13087896, 0.050710842, 0.11764759]\n",
            "G: [2.6393676, 1.5132844, 1.1260831]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14284\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13400:\n",
            "D: [0.30002758, 0.04747677, 0.08457315, 0.16797766]\n",
            "G: [2.206547, 1.0112994, 1.1952477]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14318\n",
            "1k Steps: 4:11\n",
            "Til Completion: 13h1m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13500:\n",
            "D: [0.41264224, 0.34788954, 0.014845645, 0.049907047]\n",
            "G: [2.695848, 1.7475827, 0.9482654]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14078\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13600:\n",
            "D: [0.40488014, 0.28876886, 0.034097977, 0.0820133]\n",
            "G: [2.5854836, 1.9354448, 0.6500387]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14206\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h7m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13700:\n",
            "D: [0.3028957, 0.23241505, 0.013754573, 0.05672606]\n",
            "G: [2.8350964, 1.8298464, 1.00525]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14261\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13800:\n",
            "D: [0.26743084, 0.1354101, 0.05928473, 0.072736]\n",
            "G: [2.4479218, 1.3467348, 1.101187]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14244\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 13900:\n",
            "D: [0.26765388, 0.14221133, 0.029610418, 0.095832124]\n",
            "G: [2.5848246, 1.5993912, 0.9854333]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14246\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14000:\n",
            "D: [0.23058929, 0.12020417, 0.038923003, 0.07146211]\n",
            "G: [2.6328743, 1.6503382, 0.9825361]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14379\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h56m\n",
            "\n",
            "E Mean: 0.041625194\n",
            "E Std: 1.2210172\n",
            "E Std Featurewise: 1.1407328\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14100:\n",
            "D: [0.2510387, 0.17657444, 0.007944951, 0.066519305]\n",
            "G: [2.4770038, 1.5057559, 0.9712479]\n",
            "Steps/Second: 3.71\n",
            "Steps/Hour: 13372\n",
            "1k Steps: 4:29\n",
            "Til Completion: 13h54m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14200:\n",
            "D: [0.47177476, 0.42501995, 0.006481936, 0.040272854]\n",
            "G: [2.6784863, 1.9266034, 0.751883]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14081\n",
            "1k Steps: 4:15\n",
            "Til Completion: 13h11m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14300:\n",
            "D: [0.4688444, 0.08812599, 0.14618844, 0.23453]\n",
            "G: [2.4731574, 1.2641263, 1.2090312]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14138\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h8m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14400:\n",
            "D: [0.24456179, 0.11354781, 0.027719593, 0.103294395]\n",
            "G: [2.3468947, 1.2291245, 1.1177701]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14175\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h5m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14500:\n",
            "D: [0.3128131, 0.070031404, 0.06812883, 0.17465286]\n",
            "G: [2.3518457, 1.2097783, 1.1420673]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14194\n",
            "1k Steps: 4:13\n",
            "Til Completion: 13h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14600:\n",
            "D: [0.26558024, 0.04421611, 0.09274551, 0.12861861]\n",
            "G: [2.396114, 1.2925005, 1.1036136]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14284\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h58m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14700:\n",
            "D: [0.32905385, 0.0632476, 0.10889554, 0.15691072]\n",
            "G: [2.3677359, 1.2586539, 1.109082]\n",
            "Steps/Second: 4.02\n",
            "Steps/Hour: 14486\n",
            "1k Steps: 4:8\n",
            "Til Completion: 12h47m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14800:\n",
            "D: [0.2508153, 0.092124894, 0.043371104, 0.115319304]\n",
            "G: [2.5789685, 1.4633018, 1.1156666]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14236\n",
            "1k Steps: 4:12\n",
            "Til Completion: 13h0m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 14900:\n",
            "D: [0.49846682, 0.10524918, 0.18335003, 0.20986763]\n",
            "G: [2.5765405, 1.5702177, 1.0063229]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14452\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15000:\n",
            "D: [0.47412235, 0.02776588, 0.1668859, 0.27947056]\n",
            "G: [2.0357623, 0.83588177, 1.1998805]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14237\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h59m\n",
            "\n",
            "E Mean: -0.00064524636\n",
            "E Std: 1.2105733\n",
            "E Std Featurewise: 1.1433222\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15100:\n",
            "D: [0.22847657, 0.12257537, 0.019267937, 0.086633265]\n",
            "G: [2.8248394, 1.9071217, 0.91771775]\n",
            "Steps/Second: 3.71\n",
            "Steps/Hour: 13354\n",
            "1k Steps: 4:29\n",
            "Til Completion: 13h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15200:\n",
            "D: [0.4606622, 0.07078327, 0.13746849, 0.25241044]\n",
            "G: [1.9138287, 0.6381999, 1.2756288]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14277\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15300:\n",
            "D: [0.5492934, 0.07287602, 0.20050082, 0.27591655]\n",
            "G: [1.8363051, 0.73223263, 1.1040726]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14410\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h49m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15400:\n",
            "D: [0.36187792, 0.051186547, 0.14217177, 0.1685196]\n",
            "G: [2.8231544, 1.7898265, 1.033328]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14398\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h49m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15500:\n",
            "D: [0.4419765, 0.21670058, 0.09681758, 0.12845832]\n",
            "G: [2.4561312, 1.4554164, 1.0007148]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14150\n",
            "1k Steps: 4:14\n",
            "Til Completion: 13h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15600:\n",
            "D: [0.5130189, 0.010467736, 0.23192792, 0.27062324]\n",
            "G: [1.9563774, 0.73710144, 1.219276]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14251\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15700:\n",
            "D: [0.28265375, 0.07359727, 0.06527215, 0.14378434]\n",
            "G: [2.6379917, 1.490972, 1.1470196]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14442\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h45m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15800:\n",
            "D: [0.3309005, 0.25061482, 0.025452662, 0.054833002]\n",
            "G: [2.9296317, 1.9647912, 0.9648404]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14237\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 15900:\n",
            "D: [0.27977458, 0.13257822, 0.03796333, 0.10923302]\n",
            "G: [2.6381156, 1.5406103, 1.0975053]\n",
            "Steps/Second: 4.02\n",
            "Steps/Hour: 14471\n",
            "1k Steps: 4:8\n",
            "Til Completion: 12h43m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16000:\n",
            "D: [0.66003436, 0.03502146, 0.33838263, 0.28663027]\n",
            "G: [1.3359792, 0.20348857, 1.1324906]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14385\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h47m\n",
            "\n",
            "E Mean: 0.054299597\n",
            "E Std: 1.4365602\n",
            "E Std Featurewise: 1.3228023\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16100:\n",
            "D: [0.34900913, 0.11417778, 0.069054626, 0.16577673]\n",
            "G: [2.51227, 1.3983402, 1.1139299]\n",
            "Steps/Second: 3.72\n",
            "Steps/Hour: 13396\n",
            "1k Steps: 4:28\n",
            "Til Completion: 13h43m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16200:\n",
            "D: [0.33873665, 0.1730816, 0.070325315, 0.09532973]\n",
            "G: [2.4175425, 1.2501286, 1.1674137]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14441\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h43m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16300:\n",
            "D: [0.4779226, 0.057677757, 0.18033746, 0.23990737]\n",
            "G: [2.0949993, 0.89885294, 1.1961462]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14418\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16400:\n",
            "D: [0.1890454, 0.013148434, 0.06313605, 0.112760924]\n",
            "G: [2.577198, 1.4381814, 1.1390166]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14290\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16500:\n",
            "D: [0.26245785, 0.18413436, 0.012462603, 0.06586089]\n",
            "G: [2.5328913, 1.4811629, 1.0517282]\n",
            "Steps/Second: 4.02\n",
            "Steps/Hour: 14458\n",
            "1k Steps: 4:8\n",
            "Til Completion: 12h41m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16600:\n",
            "D: [0.51193565, 0.035927378, 0.23020439, 0.24580391]\n",
            "G: [1.8164371, 0.6480808, 1.1683563]\n",
            "Steps/Second: 4.03\n",
            "Steps/Hour: 14519\n",
            "1k Steps: 4:7\n",
            "Til Completion: 12h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16700:\n",
            "D: [0.20938563, 0.08124726, 0.046374172, 0.0817642]\n",
            "G: [2.257626, 1.1576408, 1.0999851]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14257\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h51m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16800:\n",
            "D: [0.27463007, 0.056946542, 0.080840714, 0.13684282]\n",
            "G: [2.588849, 1.572507, 1.0163422]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14416\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 16900:\n",
            "D: [0.29917485, 0.09169854, 0.07133444, 0.13614185]\n",
            "G: [2.8375602, 1.8365316, 1.0010287]\n",
            "Steps/Second: 4.06\n",
            "Steps/Hour: 14601\n",
            "1k Steps: 4:6\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17000:\n",
            "D: [0.14143272, 0.015726743, 0.030804425, 0.09490155]\n",
            "G: [2.2957253, 1.2100081, 1.0857172]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14301\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h47m\n",
            "\n",
            "E Mean: -0.059024908\n",
            "E Std: 1.3972862\n",
            "E Std Featurewise: 1.2717206\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17100:\n",
            "D: [0.30854756, 0.037105188, 0.10463243, 0.16680993]\n",
            "G: [2.3928084, 1.3436782, 1.0491301]\n",
            "Steps/Second: 3.77\n",
            "Steps/Hour: 13558\n",
            "1k Steps: 4:25\n",
            "Til Completion: 13h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17200:\n",
            "D: [0.24535064, 0.12611723, 0.023103103, 0.09613031]\n",
            "G: [2.4112768, 1.4382582, 0.97301877]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14380\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17300:\n",
            "D: [0.29114822, 0.034698427, 0.08628678, 0.170163]\n",
            "G: [2.3349466, 1.2085489, 1.1263978]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14398\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h41m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17400:\n",
            "D: [0.23003456, 0.20683202, 0.00095450133, 0.022248033]\n",
            "G: [2.6231973, 1.6085517, 1.0146456]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14426\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h39m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17500:\n",
            "D: [0.4601413, 0.16669112, 0.13354686, 0.15990333]\n",
            "G: [2.5518043, 1.4361559, 1.1156484]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14380\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h41m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17600:\n",
            "D: [0.26480773, 0.09464687, 0.053884476, 0.116276376]\n",
            "G: [2.7573013, 1.7282807, 1.0290205]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14241\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17700:\n",
            "D: [0.26747173, 0.16180709, 0.02347754, 0.082187094]\n",
            "G: [2.60896, 1.7921906, 0.81676936]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14341\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17800:\n",
            "D: [0.25977245, 0.16332483, 0.03225331, 0.06419431]\n",
            "G: [2.6919246, 1.7248362, 0.9670882]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14304\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 17900:\n",
            "D: [0.26875973, 0.15184301, 0.028521305, 0.08839542]\n",
            "G: [2.844254, 1.8478363, 0.9964177]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14299\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18000:\n",
            "D: [0.35926092, 0.17265093, 0.06607146, 0.12053853]\n",
            "G: [2.226159, 1.1174673, 1.1086919]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14367\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h40m\n",
            "\n",
            "E Mean: -0.043933503\n",
            "E Std: 1.1985816\n",
            "E Std Featurewise: 1.0907769\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18100:\n",
            "D: [0.46992826, 0.047108833, 0.1948002, 0.22801922]\n",
            "G: [2.5719037, 1.4599917, 1.111912]\n",
            "Steps/Second: 3.76\n",
            "Steps/Hour: 13546\n",
            "1k Steps: 4:25\n",
            "Til Completion: 13h25m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18200:\n",
            "D: [0.40622318, 0.35818976, 0.013844775, 0.034188643]\n",
            "G: [2.7464633, 1.8742367, 0.8722265]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14306\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18300:\n",
            "D: [0.1565289, 0.10039352, 0.02389993, 0.03223546]\n",
            "G: [2.5763083, 1.7071764, 0.86913174]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14252\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18400:\n",
            "D: [0.42688817, 0.34115586, 0.014940232, 0.07079208]\n",
            "G: [2.6812563, 1.9562243, 0.72503185]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14234\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h45m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18500:\n",
            "D: [0.5173866, 0.06652059, 0.21282987, 0.23803614]\n",
            "G: [2.2732549, 1.2336515, 1.0396035]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14377\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18600:\n",
            "D: [0.49732694, 0.10978327, 0.17767137, 0.2098723]\n",
            "G: [2.3748007, 1.3057662, 1.0690345]\n",
            "Steps/Second: 4.05\n",
            "Steps/Hour: 14571\n",
            "1k Steps: 4:7\n",
            "Til Completion: 12h26m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18700:\n",
            "D: [0.35407487, 0.30726832, 0.0052131936, 0.04159333]\n",
            "G: [2.419375, 1.4187872, 1.0005877]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14293\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h41m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18800:\n",
            "D: [0.29634902, 0.03904701, 0.07648519, 0.18081681]\n",
            "G: [2.3634553, 1.335421, 1.0280342]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14447\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 18900:\n",
            "D: [0.4955611, 0.4630445, 0.0025551654, 0.02996144]\n",
            "G: [2.38602, 1.497903, 0.88811696]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14285\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h40m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19000:\n",
            "D: [0.3244983, 0.15685013, 0.05130607, 0.11634209]\n",
            "G: [2.2394037, 1.1188109, 1.1205927]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14281\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h40m\n",
            "\n",
            "E Mean: -0.09472511\n",
            "E Std: 1.2640668\n",
            "E Std Featurewise: 1.1956836\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19100:\n",
            "D: [0.33373147, 0.050474446, 0.10397594, 0.17928109]\n",
            "G: [1.9683509, 0.9002924, 1.0680585]\n",
            "Steps/Second: 3.73\n",
            "Steps/Hour: 13417\n",
            "1k Steps: 4:28\n",
            "Til Completion: 13h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19200:\n",
            "D: [0.2575636, 0.03394787, 0.08252635, 0.14108938]\n",
            "G: [2.7393303, 1.7107854, 1.028545]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14244\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h41m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19300:\n",
            "D: [0.30988914, 0.18626216, 0.039736405, 0.083890565]\n",
            "G: [2.4184155, 1.54566, 0.8727554]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14285\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h38m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19400:\n",
            "D: [0.42523012, 0.414957, 0.0, 0.010273142]\n",
            "G: [2.7044778, 1.8219666, 0.88251114]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14300\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19500:\n",
            "D: [0.25891197, 0.17644629, 0.025695268, 0.0567704]\n",
            "G: [2.681476, 1.6631578, 1.0183182]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 13998\n",
            "1k Steps: 4:17\n",
            "Til Completion: 12h53m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19600:\n",
            "D: [0.41233742, 0.18059874, 0.09253572, 0.13920295]\n",
            "G: [2.4588528, 1.5367298, 0.92212296]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14297\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19700:\n",
            "D: [0.23844217, 0.12578031, 0.042555287, 0.070106566]\n",
            "G: [2.5547156, 1.4606205, 1.094095]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14256\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h38m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19800:\n",
            "D: [0.16980872, 0.11943299, 0.0027825236, 0.047593206]\n",
            "G: [2.5143504, 1.4964818, 1.0178688]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14373\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 19900:\n",
            "D: [0.363365, 0.1376819, 0.0634678, 0.1622153]\n",
            "G: [2.1587245, 0.9887513, 1.1699733]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14110\n",
            "1k Steps: 4:15\n",
            "Til Completion: 12h45m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20000:\n",
            "D: [0.49114227, 0.055942222, 0.19917943, 0.23602062]\n",
            "G: [2.308859, 1.2872288, 1.0216303]\n",
            "Steps/Second: 3.73\n",
            "Steps/Hour: 13422\n",
            "1k Steps: 4:28\n",
            "Til Completion: 13h24m\n",
            "\n",
            "E Mean: 0.13217336\n",
            "E Std: 2.7162826\n",
            "E Std Featurewise: 2.1697993\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20100:\n",
            "D: [0.4199521, 0.042219028, 0.16162053, 0.21611252]\n",
            "G: [2.2193751, 1.1745486, 1.0448265]\n",
            "Steps/Second: 3.73\n",
            "Steps/Hour: 13435\n",
            "1k Steps: 4:27\n",
            "Til Completion: 13h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20200:\n",
            "D: [0.40283394, 0.05836209, 0.14503053, 0.1994413]\n",
            "G: [2.2551541, 1.2172067, 1.0379474]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14032\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20300:\n",
            "D: [0.37984145, 0.26248658, 0.0378544, 0.07950047]\n",
            "G: [2.8046656, 1.7969506, 1.007715]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14043\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h47m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20400:\n",
            "D: [0.1694517, 0.09946544, 0.011253847, 0.05873241]\n",
            "G: [2.427721, 1.2923446, 1.1353765]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14331\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h31m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20500:\n",
            "D: [0.44031042, 0.13476387, 0.120105386, 0.18544117]\n",
            "G: [2.3752954, 1.283188, 1.0921074]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14214\n",
            "1k Steps: 4:13\n",
            "Til Completion: 12h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20600:\n",
            "D: [0.22261006, 0.13861367, 0.024044992, 0.059951402]\n",
            "G: [2.6078327, 1.6476781, 0.96015453]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13971\n",
            "1k Steps: 4:17\n",
            "Til Completion: 12h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20700:\n",
            "D: [0.30449605, 0.03859822, 0.10811053, 0.15778728]\n",
            "G: [2.4489954, 1.3602525, 1.0887429]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 14010\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h47m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20800:\n",
            "D: [0.3559404, 0.1403788, 0.065247014, 0.1503146]\n",
            "G: [2.6100326, 1.5556676, 1.054365]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13798\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h59m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 20900:\n",
            "D: [0.23270655, 0.1522424, 0.021815367, 0.058648758]\n",
            "G: [2.6916664, 1.7256947, 0.9659717]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13892\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h53m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21000:\n",
            "D: [0.34463996, 0.3004716, 0.0043639634, 0.039804384]\n",
            "G: [3.021919, 2.1423366, 0.8795824]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13820\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h57m\n",
            "\n",
            "E Mean: -0.06404268\n",
            "E Std: 1.2287227\n",
            "E Std Featurewise: 1.1020797\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21100:\n",
            "D: [0.27121574, 0.090868466, 0.052769814, 0.12757747]\n",
            "G: [2.5376472, 1.502142, 1.0355053]\n",
            "Steps/Second: 3.6\n",
            "Steps/Hour: 12969\n",
            "1k Steps: 4:37\n",
            "Til Completion: 13h47m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21200:\n",
            "D: [0.33070296, 0.04961286, 0.09768079, 0.1834093]\n",
            "G: [2.2936726, 1.26858, 1.0250927]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14266\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21300:\n",
            "D: [0.3335833, 0.18353553, 0.0458176, 0.10423018]\n",
            "G: [2.7611923, 1.727449, 1.0337434]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14412\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21400:\n",
            "D: [0.21811166, 0.076724835, 0.03782122, 0.1035656]\n",
            "G: [2.5352736, 1.4325414, 1.1027322]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14371\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h25m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21500:\n",
            "D: [0.18876918, 0.01600597, 0.049614586, 0.12314862]\n",
            "G: [2.2248557, 1.0281129, 1.1967428]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14327\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h27m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21600:\n",
            "D: [0.31295395, 0.029845757, 0.110761575, 0.1723466]\n",
            "G: [2.519899, 1.394458, 1.1254407]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14317\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h27m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21700:\n",
            "D: [0.32647616, 0.2743488, 0.007368125, 0.044759247]\n",
            "G: [2.8388577, 1.8169372, 1.0219204]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14212\n",
            "1k Steps: 4:13\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21800:\n",
            "D: [0.28415194, 0.09813911, 0.051483884, 0.13452895]\n",
            "G: [2.5331445, 1.4695367, 1.0636079]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14128\n",
            "1k Steps: 4:14\n",
            "Til Completion: 12h36m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 21900:\n",
            "D: [0.19723117, 0.08985997, 0.030508908, 0.07686229]\n",
            "G: [2.4774277, 1.470895, 1.0065327]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14428\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22000:\n",
            "D: [0.2735278, 0.23127961, 0.0053930413, 0.03685515]\n",
            "G: [2.8457704, 1.8928137, 0.9529567]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14336\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h24m\n",
            "\n",
            "E Mean: -0.00833027\n",
            "E Std: 1.4295303\n",
            "E Std Featurewise: 1.2828933\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22100:\n",
            "D: [0.39962262, 0.11136702, 0.13007799, 0.15817761]\n",
            "G: [2.01693, 0.8856276, 1.1313026]\n",
            "Steps/Second: 3.74\n",
            "Steps/Hour: 13473\n",
            "1k Steps: 4:27\n",
            "Til Completion: 13h12m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22200:\n",
            "D: [0.22657824, 0.15622659, 0.01876107, 0.05159057]\n",
            "G: [2.8884459, 1.9773682, 0.9110775]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14210\n",
            "1k Steps: 4:13\n",
            "Til Completion: 12h30m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22300:\n",
            "D: [0.53995144, 0.11373831, 0.18610504, 0.2401081]\n",
            "G: [2.3445804, 1.2939384, 1.050642]\n",
            "Steps/Second: 4.03\n",
            "Steps/Hour: 14507\n",
            "1k Steps: 4:8\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22400:\n",
            "D: [0.35308897, 0.06988792, 0.13080338, 0.15239768]\n",
            "G: [2.2884448, 1.1817605, 1.1066842]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14312\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22500:\n",
            "D: [0.5256331, 0.06733012, 0.18913236, 0.26917064]\n",
            "G: [1.967957, 0.8460351, 1.1219219]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14268\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h26m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22600:\n",
            "D: [0.2796288, 0.047888204, 0.08814499, 0.14359562]\n",
            "G: [2.391408, 1.2936143, 1.0977938]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14221\n",
            "1k Steps: 4:13\n",
            "Til Completion: 12h28m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22700:\n",
            "D: [0.57872987, 0.16099697, 0.18943253, 0.22830033]\n",
            "G: [2.5842123, 1.6515825, 0.9326298]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14393\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h19m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22800:\n",
            "D: [0.27076042, 0.040612444, 0.05078596, 0.179362]\n",
            "G: [2.2784815, 1.1311884, 1.147293]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14354\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 22900:\n",
            "D: [0.2307015, 0.11434713, 0.058458388, 0.05789598]\n",
            "G: [2.5657399, 1.5721564, 0.99358344]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14143\n",
            "1k Steps: 4:14\n",
            "Til Completion: 12h31m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23000:\n",
            "D: [0.2596724, 0.18286699, 0.0136148855, 0.06319052]\n",
            "G: [2.577348, 1.5600679, 1.0172801]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 14018\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h37m\n",
            "\n",
            "E Mean: -0.032887746\n",
            "E Std: 1.2810975\n",
            "E Std Featurewise: 1.1672065\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23100:\n",
            "D: [0.34954894, 0.059266135, 0.10038108, 0.18990174]\n",
            "G: [2.226677, 1.0822214, 1.1444554]\n",
            "Steps/Second: 3.73\n",
            "Steps/Hour: 13434\n",
            "1k Steps: 4:27\n",
            "Til Completion: 13h10m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23200:\n",
            "D: [0.40988857, 0.042035364, 0.15442094, 0.21343224]\n",
            "G: [2.3005943, 1.1510016, 1.1495929]\n",
            "Steps/Second: 4.01\n",
            "Steps/Hour: 14448\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23300:\n",
            "D: [0.25406188, 0.06400347, 0.057053216, 0.1330052]\n",
            "G: [2.0106926, 0.82613814, 1.1845543]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14247\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23400:\n",
            "D: [0.25149983, 0.13404053, 0.045227244, 0.07223207]\n",
            "G: [3.0438147, 2.1390324, 0.90478235]\n",
            "Steps/Second: 4.02\n",
            "Steps/Hour: 14464\n",
            "1k Steps: 4:8\n",
            "Til Completion: 12h12m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23500:\n",
            "D: [0.23242715, 0.13096946, 0.010886785, 0.090570904]\n",
            "G: [2.8274333, 1.8819079, 0.94552535]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14405\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23600:\n",
            "D: [0.41535044, 0.040443942, 0.16251469, 0.21239182]\n",
            "G: [2.3849754, 1.3103429, 1.0746325]\n",
            "Steps/Second: 4.0\n",
            "Steps/Hour: 14401\n",
            "1k Steps: 4:9\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23700:\n",
            "D: [0.22642429, 0.020931222, 0.06740213, 0.13809094]\n",
            "G: [2.104085, 0.97879994, 1.1252849]\n",
            "Steps/Second: 3.99\n",
            "Steps/Hour: 14362\n",
            "1k Steps: 4:10\n",
            "Til Completion: 12h16m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23800:\n",
            "D: [0.23668608, 0.08890778, 0.039481714, 0.10829659]\n",
            "G: [2.370009, 1.3612453, 1.0087636]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14261\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h21m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 23900:\n",
            "D: [0.6213496, 0.07136417, 0.25048423, 0.29950118]\n",
            "G: [2.2740672, 1.1732848, 1.1007824]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14302\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h18m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24000:\n",
            "D: [0.5767653, 0.0149632655, 0.24663326, 0.31516874]\n",
            "G: [1.8152565, 0.6872741, 1.1279824]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14181\n",
            "1k Steps: 4:13\n",
            "Til Completion: 12h24m\n",
            "\n",
            "E Mean: 0.038332827\n",
            "E Std: 1.2011591\n",
            "E Std Featurewise: 1.0901238\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24100:\n",
            "D: [0.3722384, 0.08392395, 0.119028695, 0.16928576]\n",
            "G: [2.3542266, 1.3299356, 1.024291]\n",
            "Steps/Second: 3.76\n",
            "Steps/Hour: 13549\n",
            "1k Steps: 4:25\n",
            "Til Completion: 12h58m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24200:\n",
            "D: [0.34141195, 0.14048341, 0.057734914, 0.14319362]\n",
            "G: [2.4737282, 1.3770647, 1.0966634]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14262\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h19m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24300:\n",
            "D: [0.5014154, 0.037874125, 0.17986406, 0.28367716]\n",
            "G: [2.1964116, 1.145342, 1.0510697]\n",
            "Steps/Second: 3.98\n",
            "Steps/Hour: 14340\n",
            "1k Steps: 4:11\n",
            "Til Completion: 12h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24400:\n",
            "D: [0.41731778, 0.33454603, 0.013377262, 0.06939451]\n",
            "G: [2.4197516, 1.5113971, 0.90835464]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14122\n",
            "1k Steps: 4:14\n",
            "Til Completion: 12h26m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24500:\n",
            "D: [0.2992332, 0.14752838, 0.041151207, 0.11055361]\n",
            "G: [2.5977647, 1.5617831, 1.0359817]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14110\n",
            "1k Steps: 4:15\n",
            "Til Completion: 12h26m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24600:\n",
            "D: [0.14060973, 0.049538564, 0.018434485, 0.07263668]\n",
            "G: [2.4031985, 1.4553103, 0.9478882]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14091\n",
            "1k Steps: 4:15\n",
            "Til Completion: 12h26m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24700:\n",
            "D: [0.26063284, 0.056043133, 0.076289505, 0.1283002]\n",
            "G: [2.6275218, 1.5267628, 1.1007589]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14112\n",
            "1k Steps: 4:15\n",
            "Til Completion: 12h25m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24800:\n",
            "D: [0.342534, 0.0908484, 0.09289162, 0.15879399]\n",
            "G: [2.537788, 1.4168259, 1.1209621]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13940\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h34m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 24900:\n",
            "D: [0.2939108, 0.058580868, 0.09687816, 0.13845177]\n",
            "G: [2.5582106, 1.5637913, 0.9944194]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 14009\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25000:\n",
            "D: [0.19362934, 0.03330799, 0.057808444, 0.10251291]\n",
            "G: [1.7939559, 0.68694556, 1.1070104]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13698\n",
            "1k Steps: 4:22\n",
            "Til Completion: 12h46m\n",
            "\n",
            "E Mean: 0.06699889\n",
            "E Std: 1.1346632\n",
            "E Std Featurewise: 1.0002891\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25100:\n",
            "D: [0.32016936, 0.1820702, 0.037607346, 0.10049182]\n",
            "G: [2.2525072, 1.228811, 1.0236962]\n",
            "Steps/Second: 3.63\n",
            "Steps/Hour: 13065\n",
            "1k Steps: 4:35\n",
            "Til Completion: 13h23m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25200:\n",
            "D: [0.30344728, 0.03471382, 0.12004523, 0.14868823]\n",
            "G: [2.230416, 1.1814928, 1.0489233]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13823\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h38m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25300:\n",
            "D: [0.39163876, 0.046464875, 0.12254071, 0.22263315]\n",
            "G: [2.1638708, 1.0632374, 1.1006334]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14027\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h27m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25400:\n",
            "D: [0.29904294, 0.0043287836, 0.10380454, 0.19090962]\n",
            "G: [2.072176, 1.0304024, 1.0417736]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13937\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h31m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25500:\n",
            "D: [0.11258644, 0.04916119, 0.013881559, 0.049543697]\n",
            "G: [2.4236784, 1.3914065, 1.0322717]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14143\n",
            "1k Steps: 4:14\n",
            "Til Completion: 12h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25600:\n",
            "D: [0.324588, 0.099548094, 0.067238584, 0.15780133]\n",
            "G: [2.5399797, 1.4220176, 1.1179621]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14184\n",
            "1k Steps: 4:13\n",
            "Til Completion: 12h17m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25700:\n",
            "D: [0.3516298, 0.11419432, 0.120202124, 0.117233336]\n",
            "G: [2.300233, 1.3098366, 0.99039614]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14240\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25800:\n",
            "D: [0.369391, 0.09742084, 0.1008193, 0.17115086]\n",
            "G: [2.3496914, 1.2594328, 1.0902586]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14238\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 25900:\n",
            "D: [0.55299777, 0.09945369, 0.23884453, 0.21469958]\n",
            "G: [2.5219486, 1.6289252, 0.8930234]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14271\n",
            "1k Steps: 4:12\n",
            "Til Completion: 12h11m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26000:\n",
            "D: [0.33971882, 0.10846561, 0.07889871, 0.15235451]\n",
            "G: [2.183229, 1.1014447, 1.0817841]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13918\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h30m\n",
            "\n",
            "E Mean: 0.01824094\n",
            "E Std: 1.1173158\n",
            "E Std Featurewise: 1.0136874\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26100:\n",
            "D: [0.1907813, 0.09071165, 0.028606968, 0.07146267]\n",
            "G: [2.348502, 1.3455731, 1.0029289]\n",
            "Steps/Second: 3.63\n",
            "Steps/Hour: 13064\n",
            "1k Steps: 4:35\n",
            "Til Completion: 13h18m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26200:\n",
            "D: [0.386371, 0.0942172, 0.10700314, 0.18515065]\n",
            "G: [2.4079804, 1.3830181, 1.0249624]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13798\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h35m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26300:\n",
            "D: [0.31562287, 0.11328223, 0.07059782, 0.1317428]\n",
            "G: [2.359912, 1.2968812, 1.0630307]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14066\n",
            "1k Steps: 4:15\n",
            "Til Completion: 12h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26400:\n",
            "D: [0.3159587, 0.10581922, 0.06068504, 0.14945444]\n",
            "G: [2.5412817, 1.625752, 0.91552967]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13762\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h36m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26500:\n",
            "D: [0.3421052, 0.11171724, 0.08083546, 0.14955252]\n",
            "G: [2.180778, 1.0496309, 1.1311471]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13883\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h29m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26600:\n",
            "D: [0.29274124, 0.18671934, 0.020560188, 0.08546169]\n",
            "G: [2.565735, 1.6120657, 0.9536695]\n",
            "Steps/Second: 3.79\n",
            "Steps/Hour: 13643\n",
            "1k Steps: 4:23\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26700:\n",
            "D: [0.3406752, 0.13690932, 0.099785395, 0.10398049]\n",
            "G: [2.4512062, 1.4830085, 0.96819764]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13814\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26800:\n",
            "D: [0.36123875, 0.039141424, 0.15126522, 0.1708321]\n",
            "G: [2.2575734, 1.1885767, 1.0689967]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13888\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h28m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 26900:\n",
            "D: [0.31439823, 0.038316328, 0.12367172, 0.1524102]\n",
            "G: [2.5138066, 1.4971824, 1.0166242]\n",
            "Steps/Second: 3.78\n",
            "Steps/Hour: 13616\n",
            "1k Steps: 4:24\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27000:\n",
            "D: [0.2730294, 0.050553277, 0.060582954, 0.16189314]\n",
            "G: [2.616136, 1.5350976, 1.0810386]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13830\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h30m\n",
            "\n",
            "E Mean: 0.022138143\n",
            "E Std: 1.1528893\n",
            "E Std Featurewise: 1.0626842\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27100:\n",
            "D: [0.24107887, 0.18017656, 0.022016743, 0.03888556]\n",
            "G: [2.6374426, 1.5894275, 1.0480151]\n",
            "Steps/Second: 3.6\n",
            "Steps/Hour: 12965\n",
            "1k Steps: 4:37\n",
            "Til Completion: 13h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27200:\n",
            "D: [0.31549633, 0.029193128, 0.106089935, 0.18021324]\n",
            "G: [2.5838335, 1.653704, 0.9301294]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13752\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27300:\n",
            "D: [0.34558088, 0.08709221, 0.11627717, 0.14221148]\n",
            "G: [2.599063, 1.5808548, 1.018208]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13755\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27400:\n",
            "D: [0.48395604, 0.08357982, 0.18610033, 0.2142759]\n",
            "G: [2.0822093, 1.0292251, 1.0529842]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13767\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27500:\n",
            "D: [0.28227785, 0.16118625, 0.044344798, 0.07674681]\n",
            "G: [2.5175471, 1.5226979, 0.9948491]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13937\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h22m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27600:\n",
            "D: [0.476914, 0.107783, 0.17152357, 0.19760743]\n",
            "G: [2.7828386, 1.8681467, 0.9146919]\n",
            "Steps/Second: 3.81\n",
            "Steps/Hour: 13700\n",
            "1k Steps: 4:22\n",
            "Til Completion: 12h35m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27700:\n",
            "D: [0.29069793, 0.10486843, 0.04887013, 0.13695937]\n",
            "G: [2.3534532, 1.384738, 0.9687153]\n",
            "Steps/Second: 3.81\n",
            "Steps/Hour: 13714\n",
            "1k Steps: 4:22\n",
            "Til Completion: 12h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27800:\n",
            "D: [0.425867, 0.40731597, 0.0010476243, 0.017503405]\n",
            "G: [2.6287205, 1.7263346, 0.9023859]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13696\n",
            "1k Steps: 4:22\n",
            "Til Completion: 12h34m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 27900:\n",
            "D: [0.39491737, 0.3247884, 0.0009863991, 0.06914258]\n",
            "G: [2.4828079, 1.5696754, 0.9131325]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13836\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h26m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28000:\n",
            "D: [0.24669535, 0.072128266, 0.06366147, 0.11090562]\n",
            "G: [2.6084046, 1.5701722, 1.0382326]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13855\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h24m\n",
            "\n",
            "E Mean: 0.052879367\n",
            "E Std: 1.1112487\n",
            "E Std Featurewise: 1.027005\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28100:\n",
            "D: [0.3105672, 0.26216176, 0.014693804, 0.033711642]\n",
            "G: [2.9313107, 1.9816929, 0.9496177]\n",
            "Steps/Second: 3.6\n",
            "Steps/Hour: 12968\n",
            "1k Steps: 4:37\n",
            "Til Completion: 13h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28200:\n",
            "D: [0.28080627, 0.15838313, 0.040867977, 0.081555165]\n",
            "G: [2.5247145, 1.5655825, 0.9591319]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13741\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h30m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28300:\n",
            "D: [0.23415563, 0.077929445, 0.06258968, 0.0936365]\n",
            "G: [2.5602174, 1.5494319, 1.0107856]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13774\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h27m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28400:\n",
            "D: [0.29554647, 0.2796352, 0.00035323948, 0.015558019]\n",
            "G: [2.9721313, 2.0221372, 0.94999415]\n",
            "Steps/Second: 3.81\n",
            "Steps/Hour: 13712\n",
            "1k Steps: 4:22\n",
            "Til Completion: 12h30m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28500:\n",
            "D: [0.3349781, 0.019953037, 0.14016855, 0.17485651]\n",
            "G: [2.1370242, 1.0897636, 1.0472605]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13895\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28600:\n",
            "D: [0.2864179, 0.17841801, 0.023866203, 0.08413368]\n",
            "G: [2.7794867, 1.767095, 1.0123918]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13821\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28700:\n",
            "D: [0.16228712, 0.15337458, 0.0, 0.008912541]\n",
            "G: [2.9681802, 2.0158012, 0.95237905]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13876\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h20m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28800:\n",
            "D: [0.42068183, 0.07138737, 0.15740213, 0.19189231]\n",
            "G: [2.062589, 0.95059276, 1.1119962]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13978\n",
            "1k Steps: 4:17\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 28900:\n",
            "D: [0.45533693, 0.042485964, 0.15855527, 0.2542957]\n",
            "G: [2.2244377, 1.1222541, 1.1021836]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13741\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h27m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29000:\n",
            "D: [0.33602887, 0.029282715, 0.17854969, 0.12819648]\n",
            "G: [2.121829, 1.0521301, 1.069699]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14106\n",
            "1k Steps: 4:15\n",
            "Til Completion: 12h7m\n",
            "\n",
            "E Mean: -0.03281395\n",
            "E Std: 1.0244564\n",
            "E Std Featurewise: 0.92982167\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29100:\n",
            "D: [0.31781802, 0.102522984, 0.05912379, 0.15617123]\n",
            "G: [2.5479505, 1.5623522, 0.9855983]\n",
            "Steps/Second: 3.7\n",
            "Steps/Hour: 13337\n",
            "1k Steps: 4:29\n",
            "Til Completion: 12h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29200:\n",
            "D: [0.33728486, 0.064004794, 0.106208846, 0.16707121]\n",
            "G: [2.2065744, 1.1271622, 1.0794122]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14039\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h9m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29300:\n",
            "D: [0.4796933, 0.41596183, 0.011600504, 0.052130975]\n",
            "G: [2.8236117, 1.8106904, 1.0129213]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13752\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h24m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29400:\n",
            "D: [0.32370463, 0.0021878742, 0.12587576, 0.195641]\n",
            "G: [2.196975, 1.1129308, 1.0840442]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13867\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h18m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29500:\n",
            "D: [0.26857582, 0.050529674, 0.08633377, 0.13171238]\n",
            "G: [1.9294028, 0.7663784, 1.1630244]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13909\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h15m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29600:\n",
            "D: [0.16235779, 0.10206175, 0.0150783695, 0.04521768]\n",
            "G: [2.8277798, 1.9159664, 0.9118135]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13778\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h22m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29700:\n",
            "D: [0.3134343, 0.071257174, 0.117436424, 0.12474069]\n",
            "G: [2.5877802, 1.5447786, 1.0430017]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14152\n",
            "1k Steps: 4:14\n",
            "Til Completion: 12h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29800:\n",
            "D: [0.48908138, 0.07361174, 0.23488212, 0.18058755]\n",
            "G: [2.4216511, 1.4135346, 1.0081165]\n",
            "Steps/Second: 3.97\n",
            "Steps/Hour: 14287\n",
            "1k Steps: 4:11\n",
            "Til Completion: 11h54m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 29900:\n",
            "D: [0.5676506, 0.13054785, 0.18829194, 0.24881081]\n",
            "G: [2.4240575, 1.403605, 1.0204524]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14033\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h7m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30000:\n",
            "D: [0.26139414, 0.17901592, 0.014403831, 0.06797439]\n",
            "G: [2.7118936, 1.7188263, 0.9930673]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 14005\n",
            "1k Steps: 4:17\n",
            "Til Completion: 12h8m\n",
            "\n",
            "E Mean: -0.05523844\n",
            "E Std: 1.1959758\n",
            "E Std Featurewise: 1.0835842\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30100:\n",
            "D: [0.30881953, 0.012948424, 0.12036471, 0.1755064]\n",
            "G: [2.1789443, 1.0673478, 1.1115966]\n",
            "Steps/Second: 3.67\n",
            "Steps/Hour: 13224\n",
            "1k Steps: 4:32\n",
            "Til Completion: 12h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30200:\n",
            "D: [0.21886443, 0.11150521, 0.035571277, 0.07178794]\n",
            "G: [2.4832819, 1.4402359, 1.043046]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13898\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h13m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30300:\n",
            "D: [0.3983053, 0.15235734, 0.09657545, 0.14937252]\n",
            "G: [2.310106, 1.2555275, 1.0545785]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13927\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h11m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30400:\n",
            "D: [0.5084036, 0.050532706, 0.18480764, 0.27306324]\n",
            "G: [1.9021106, 0.7313937, 1.1707169]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13854\n",
            "1k Steps: 4:19\n",
            "Til Completion: 12h14m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30500:\n",
            "D: [0.35633463, 0.06046226, 0.15146485, 0.14440751]\n",
            "G: [2.4774175, 1.4356904, 1.0417271]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14045\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30600:\n",
            "D: [0.31114337, 0.26295185, 0.0030122846, 0.04517922]\n",
            "G: [2.863469, 1.8863528, 0.97711605]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14157\n",
            "1k Steps: 4:14\n",
            "Til Completion: 11h57m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30700:\n",
            "D: [0.4020037, 0.112937964, 0.1225028, 0.16656294]\n",
            "G: [2.4991996, 1.6461021, 0.85309756]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14139\n",
            "1k Steps: 4:14\n",
            "Til Completion: 11h58m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30800:\n",
            "D: [0.34367922, 0.3063454, 0.0023338255, 0.035]\n",
            "G: [2.6030474, 1.6279037, 0.9751438]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14033\n",
            "1k Steps: 4:16\n",
            "Til Completion: 12h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 30900:\n",
            "D: [0.22285536, 0.0026761293, 0.079000995, 0.14117824]\n",
            "G: [2.3431444, 1.2707136, 1.0724307]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13927\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h8m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31000:\n",
            "D: [0.31643456, 0.020873576, 0.12597346, 0.16958751]\n",
            "G: [1.947744, 0.8094462, 1.1382978]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13765\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h16m\n",
            "\n",
            "E Mean: 0.012897644\n",
            "E Std: 1.112958\n",
            "E Std Featurewise: 1.0224518\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31100:\n",
            "D: [0.19721149, 0.15706344, 0.0072276536, 0.032920387]\n",
            "G: [2.9412858, 1.9904926, 0.95079327]\n",
            "Steps/Second: 3.69\n",
            "Steps/Hour: 13292\n",
            "1k Steps: 4:30\n",
            "Til Completion: 12h42m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31200:\n",
            "D: [0.39638662, 0.20191428, 0.07193758, 0.122534744]\n",
            "G: [2.5457358, 1.5431714, 1.0025644]\n",
            "Steps/Second: 3.89\n",
            "Steps/Hour: 13990\n",
            "1k Steps: 4:17\n",
            "Til Completion: 12h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31300:\n",
            "D: [0.38183865, 0.37765926, 0.0, 0.0041793883]\n",
            "G: [2.8220885, 1.9362862, 0.88580227]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14243\n",
            "1k Steps: 4:12\n",
            "Til Completion: 11h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31400:\n",
            "D: [0.24356532, 0.12459734, 0.053830553, 0.06513743]\n",
            "G: [2.0532627, 1.0410275, 1.0122352]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14120\n",
            "1k Steps: 4:14\n",
            "Til Completion: 11h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31500:\n",
            "D: [0.40710855, 0.051997162, 0.1566917, 0.1984197]\n",
            "G: [1.9785687, 0.9351014, 1.0434673]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14188\n",
            "1k Steps: 4:13\n",
            "Til Completion: 11h52m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31600:\n",
            "D: [0.43687528, 0.40550175, 0.0035017766, 0.027871743]\n",
            "G: [2.6300263, 1.697567, 0.93245924]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14122\n",
            "1k Steps: 4:14\n",
            "Til Completion: 11h55m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31700:\n",
            "D: [0.39018962, 0.1438233, 0.08252296, 0.16384336]\n",
            "G: [2.2278233, 1.139713, 1.0881102]\n",
            "Steps/Second: 3.93\n",
            "Steps/Hour: 14136\n",
            "1k Steps: 4:14\n",
            "Til Completion: 11h54m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31800:\n",
            "D: [0.38269278, 0.017841209, 0.16726966, 0.19758192]\n",
            "G: [2.2688272, 1.1691658, 1.0996614]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14048\n",
            "1k Steps: 4:16\n",
            "Til Completion: 11h58m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 31900:\n",
            "D: [0.20560472, 0.07360123, 0.035201658, 0.09680183]\n",
            "G: [2.4519467, 1.3876512, 1.0642955]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14189\n",
            "1k Steps: 4:13\n",
            "Til Completion: 11h50m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32000:\n",
            "D: [0.48552373, 0.15559384, 0.12462261, 0.20530728]\n",
            "G: [2.2769556, 1.23085, 1.0461056]\n",
            "Steps/Second: 3.87\n",
            "Steps/Hour: 13928\n",
            "1k Steps: 4:18\n",
            "Til Completion: 12h3m\n",
            "\n",
            "E Mean: -0.023748234\n",
            "E Std: 1.1756735\n",
            "E Std Featurewise: 1.0573902\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32100:\n",
            "D: [0.38431942, 0.28969532, 0.02259639, 0.07202772]\n",
            "G: [2.5790224, 1.6418319, 0.9371904]\n",
            "Steps/Second: 3.71\n",
            "Steps/Hour: 13367\n",
            "1k Steps: 4:29\n",
            "Til Completion: 12h33m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32200:\n",
            "D: [0.41343504, 0.09568258, 0.12790793, 0.18984452]\n",
            "G: [2.7002506, 1.7790513, 0.92119944]\n",
            "Steps/Second: 3.95\n",
            "Steps/Hour: 14233\n",
            "1k Steps: 4:12\n",
            "Til Completion: 11h47m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32300:\n",
            "D: [0.27840194, 0.105210975, 0.061886534, 0.11130443]\n",
            "G: [2.5207977, 1.5543474, 0.9664502]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14176\n",
            "1k Steps: 4:13\n",
            "Til Completion: 11h49m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32400:\n",
            "D: [0.3060531, 0.15234733, 0.061510783, 0.092195004]\n",
            "G: [2.9103196, 1.9350142, 0.9753053]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14269\n",
            "1k Steps: 4:12\n",
            "Til Completion: 11h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32500:\n",
            "D: [0.36240423, 0.1437703, 0.07980671, 0.1388272]\n",
            "G: [2.6647673, 1.7759364, 0.88883096]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14032\n",
            "1k Steps: 4:16\n",
            "Til Completion: 11h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32600:\n",
            "D: [0.37895614, 0.14523457, 0.07472162, 0.15899993]\n",
            "G: [2.5294697, 1.5616204, 0.9678494]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13967\n",
            "1k Steps: 4:17\n",
            "Til Completion: 11h59m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32700:\n",
            "D: [0.42158002, 0.107398435, 0.12608525, 0.18809634]\n",
            "G: [2.4735994, 1.453069, 1.0205305]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14093\n",
            "1k Steps: 4:15\n",
            "Til Completion: 11h52m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32800:\n",
            "D: [0.18242636, 0.10911999, 0.021677347, 0.05162902]\n",
            "G: [2.3430734, 1.4287506, 0.91432273]\n",
            "Steps/Second: 3.96\n",
            "Steps/Hour: 14246\n",
            "1k Steps: 4:12\n",
            "Til Completion: 11h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 32900:\n",
            "D: [0.36168015, 0.11111656, 0.086989686, 0.16357392]\n",
            "G: [1.9313698, 0.8477723, 1.0835974]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13974\n",
            "1k Steps: 4:17\n",
            "Til Completion: 11h57m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33000:\n",
            "D: [0.17897859, 0.03009564, 0.04715815, 0.1017248]\n",
            "G: [2.1033485, 0.9911828, 1.1121657]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13960\n",
            "1k Steps: 4:17\n",
            "Til Completion: 11h57m\n",
            "\n",
            "E Mean: -0.013718676\n",
            "E Std: 1.1726519\n",
            "E Std Featurewise: 1.0325373\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33100:\n",
            "D: [0.46984866, 0.43366176, 0.0022105481, 0.033976357]\n",
            "G: [2.4634929, 1.5768552, 0.8866378]\n",
            "Steps/Second: 3.7\n",
            "Steps/Hour: 13308\n",
            "1k Steps: 4:30\n",
            "Til Completion: 12h32m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33200:\n",
            "D: [0.21732828, 0.04814137, 0.0690599, 0.10012701]\n",
            "G: [2.2433317, 1.2897673, 0.95356435]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14059\n",
            "1k Steps: 4:16\n",
            "Til Completion: 11h51m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33300:\n",
            "D: [0.2274153, 0.17330667, 0.011792393, 0.042316236]\n",
            "G: [2.7485578, 1.7896503, 0.9589074]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14092\n",
            "1k Steps: 4:15\n",
            "Til Completion: 11h49m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33400:\n",
            "D: [0.4014262, 0.15367562, 0.103909105, 0.14384148]\n",
            "G: [2.6062317, 1.5269213, 1.0793104]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14195\n",
            "1k Steps: 4:13\n",
            "Til Completion: 11h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33500:\n",
            "D: [0.34570628, 0.23432074, 0.038360015, 0.07302551]\n",
            "G: [2.9092216, 1.9804127, 0.92880887]\n",
            "Steps/Second: 3.91\n",
            "Steps/Hour: 14092\n",
            "1k Steps: 4:15\n",
            "Til Completion: 11h48m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33600:\n",
            "D: [0.16301861, 0.10336102, 0.012868401, 0.046789207]\n",
            "G: [2.6667044, 1.6898398, 0.9768646]\n",
            "Steps/Second: 3.94\n",
            "Steps/Hour: 14177\n",
            "1k Steps: 4:13\n",
            "Til Completion: 11h44m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33700:\n",
            "D: [0.2875453, 0.12780622, 0.061476372, 0.09826269]\n",
            "G: [2.4964585, 1.4820533, 1.0144051]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13807\n",
            "1k Steps: 4:20\n",
            "Til Completion: 12h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33800:\n",
            "D: [0.24167638, 0.07052827, 0.0452241, 0.125924]\n",
            "G: [2.4395392, 1.3972158, 1.0423234]\n",
            "Steps/Second: 3.83\n",
            "Steps/Hour: 13782\n",
            "1k Steps: 4:21\n",
            "Til Completion: 12h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 33900:\n",
            "D: [0.35596, 0.29278046, 0.006576825, 0.056602724]\n",
            "G: [2.6387377, 1.6740863, 0.96465147]\n",
            "Steps/Second: 3.92\n",
            "Steps/Hour: 14113\n",
            "1k Steps: 4:15\n",
            "Til Completion: 11h46m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34000:\n",
            "D: [0.2731443, 0.19505398, 0.019675998, 0.05841434]\n",
            "G: [2.8535285, 1.865566, 0.98796237]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13868\n",
            "1k Steps: 4:19\n",
            "Til Completion: 11h58m\n",
            "\n",
            "E Mean: 0.0004753098\n",
            "E Std: 1.2044164\n",
            "E Std Featurewise: 1.082495\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34100:\n",
            "D: [0.3170453, 0.14834057, 0.05341912, 0.1152856]\n",
            "G: [2.8527699, 1.8489096, 1.0038602]\n",
            "Steps/Second: 3.69\n",
            "Steps/Hour: 13301\n",
            "1k Steps: 4:30\n",
            "Til Completion: 12h28m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34200:\n",
            "D: [0.38763642, 0.22388744, 0.0388574, 0.12489159]\n",
            "G: [2.53153, 1.4794323, 1.0520976]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13740\n",
            "1k Steps: 4:22\n",
            "Til Completion: 12h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34300:\n",
            "D: [0.35378906, 0.13569683, 0.08415158, 0.13394065]\n",
            "G: [2.4030173, 1.3959268, 1.0070904]\n",
            "Steps/Second: 3.79\n",
            "Steps/Hour: 13651\n",
            "1k Steps: 4:23\n",
            "Til Completion: 12h8m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34400:\n",
            "D: [0.22257258, 0.20611078, 0.0017804634, 0.0146813365]\n",
            "G: [3.013802, 2.0820663, 0.93173575]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13862\n",
            "1k Steps: 4:19\n",
            "Til Completion: 11h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34500:\n",
            "D: [0.20895109, 0.07669887, 0.048525713, 0.083726496]\n",
            "G: [2.1945322, 1.1392615, 1.0552707]\n",
            "Steps/Second: 3.85\n",
            "Steps/Hour: 13842\n",
            "1k Steps: 4:20\n",
            "Til Completion: 11h57m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34600:\n",
            "D: [0.35549515, 0.0, 0.13297547, 0.22251967]\n",
            "G: [2.1248555, 1.011339, 1.1135166]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13897\n",
            "1k Steps: 4:19\n",
            "Til Completion: 11h54m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34700:\n",
            "D: [0.32009915, 0.12545724, 0.059007563, 0.13563433]\n",
            "G: [2.2966003, 1.2590208, 1.0375795]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13903\n",
            "1k Steps: 4:18\n",
            "Til Completion: 11h53m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34800:\n",
            "D: [0.4037122, 0.0039670784, 0.17380077, 0.22594437]\n",
            "G: [1.6772652, 0.61912775, 1.0581374]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13839\n",
            "1k Steps: 4:20\n",
            "Til Completion: 11h56m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 34900:\n",
            "D: [0.26695955, 0.19891308, 0.008497212, 0.059549242]\n",
            "G: [2.6980784, 1.8510501, 0.84702826]\n",
            "Steps/Second: 3.78\n",
            "Steps/Hour: 13592\n",
            "1k Steps: 4:24\n",
            "Til Completion: 12h8m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35000:\n",
            "D: [0.24694286, 0.088078186, 0.06570276, 0.093161926]\n",
            "G: [2.5972176, 1.6643858, 0.9328319]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13961\n",
            "1k Steps: 4:17\n",
            "Til Completion: 11h49m\n",
            "\n",
            "E Mean: -0.07293341\n",
            "E Std: 1.2098465\n",
            "E Std Featurewise: 1.1059119\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35100:\n",
            "D: [0.34480867, 0.11577147, 0.08554957, 0.14348763]\n",
            "G: [2.2273598, 1.1760778, 1.0512819]\n",
            "Steps/Second: 3.63\n",
            "Steps/Hour: 13068\n",
            "1k Steps: 4:35\n",
            "Til Completion: 12h37m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35200:\n",
            "D: [0.26381546, 0.049825057, 0.053425625, 0.16056478]\n",
            "G: [2.2137098, 1.1175665, 1.0961432]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13665\n",
            "1k Steps: 4:23\n",
            "Til Completion: 12h3m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35300:\n",
            "D: [0.5125835, 0.10849106, 0.1767695, 0.22732295]\n",
            "G: [2.2086594, 1.1852438, 1.0234156]\n",
            "Steps/Second: 3.8\n",
            "Steps/Hour: 13680\n",
            "1k Steps: 4:23\n",
            "Til Completion: 12h2m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35400:\n",
            "D: [0.23931983, 0.10830256, 0.046432037, 0.084585235]\n",
            "G: [2.863721, 1.9899663, 0.87375474]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13829\n",
            "1k Steps: 4:20\n",
            "Til Completion: 11h54m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35500:\n",
            "D: [0.25313824, 0.21838132, 0.0010327809, 0.03372416]\n",
            "G: [2.4684873, 1.486467, 0.9820204]\n",
            "Steps/Second: 3.82\n",
            "Steps/Hour: 13756\n",
            "1k Steps: 4:21\n",
            "Til Completion: 11h57m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35600:\n",
            "D: [0.2592455, 0.109992504, 0.06808498, 0.081168026]\n",
            "G: [2.4103668, 1.3318706, 1.0784962]\n",
            "Steps/Second: 3.78\n",
            "Steps/Hour: 13610\n",
            "1k Steps: 4:24\n",
            "Til Completion: 12h4m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35700:\n",
            "D: [0.25879234, 0.1737181, 0.026204335, 0.0588699]\n",
            "G: [2.8652573, 1.9428753, 0.9223819]\n",
            "Steps/Second: 3.84\n",
            "Steps/Hour: 13837\n",
            "1k Steps: 4:20\n",
            "Til Completion: 11h52m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35800:\n",
            "D: [0.36517447, 0.07759361, 0.097069845, 0.19051103]\n",
            "G: [2.2662964, 1.2514927, 1.0148035]\n",
            "Steps/Second: 3.86\n",
            "Steps/Hour: 13880\n",
            "1k Steps: 4:19\n",
            "Til Completion: 11h49m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 35900:\n",
            "D: [0.27592748, 0.0862239, 0.063970536, 0.12573303]\n",
            "G: [2.8145738, 1.8366452, 0.97792864]\n",
            "Steps/Second: 3.88\n",
            "Steps/Hour: 13964\n",
            "1k Steps: 4:17\n",
            "Til Completion: 11h45m\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 36000:\n",
            "D: [0.5189148, 0.062445544, 0.20376797, 0.25270128]\n",
            "G: [2.2238855, 1.1804523, 1.0434331]\n",
            "Steps/Second: 3.9\n",
            "Steps/Hour: 14057\n",
            "1k Steps: 4:16\n",
            "Til Completion: 11h40m\n",
            "\n",
            "E Mean: -0.046081398\n",
            "E Std: 1.066295\n",
            "E Std Featurewise: 0.9894937\n",
            "\n",
            "  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100% \n",
            "\n",
            "\n",
            "\n",
            "Round 36100:\n",
            "D: [0.3786106, 0.075594485, 0.12292969, 0.18008642]\n",
            "G: [2.1601799, 1.1751201, 0.98505974]\n",
            "Steps/Second: 3.64\n",
            "Steps/Hour: 13089\n",
            "1k Steps: 4:35\n",
            "Til Completion: 12h31m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EfSgU10nhv5",
        "colab_type": "text"
      },
      "source": [
        "# Anomaly detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66gKyC_B0N4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE A RANDOM NORMAL NOISE THAT IS THE INPUT OF THE GENERATOR\n",
        "def mynoise(n):\n",
        "    return np.random.normal(0.0, 1.0, size = [n, 64])\n",
        "\n",
        "# CLASS TO DEFINE SOME PARAMETERS \n",
        "class DataParm(Enum):\n",
        "    common_path = './model'\n",
        "    common_path_efficient = './model2'\n",
        "    image_size_127_5 = 127.5\n",
        "    batch_size_64 = 64\n",
        "\n",
        "# LOSS FUNCTION OF THE ANOMALY DETECTOR, THIS IS USED TO FIND THE \n",
        "# POINT z' IN THE LATENT SPACE Z THAT GENERATE THE MOST SIMILAR \n",
        "# IMAGE TO THE QUERY \n",
        "def sum_of_residual(y_true: np.array, y_pred: np.array):\n",
        "    return K.sum(K.abs(y_true - y_pred))\n",
        "\n",
        "class FeatureExtractorParam(Enum):\n",
        "    loss_binary_crossentropy = \"binary_crossentropy\"\n",
        "    optimizer_rmsprop = \"rmsprop\"\n",
        "    feature_extract_layer_first_conv = -65\n",
        "\n",
        "# FEATURE EXTRACTOR, THIS IS USED TO CREATE THE FEATURE \n",
        "# REPRESENTATION OF THE QUERY AND FOR THE GENERATED IMAGE\n",
        "def feature_extractor(d: Model=None, common_path: str=DataParm.common_path.value) -> Model:\n",
        "    intermidiate_model = Model(inputs=d.layers[0].input, outputs=d.layers[FeatureExtractorParam.feature_extract_layer_first_conv.value].output)\n",
        "    intermidiate_model.compile(loss=FeatureExtractorParam.loss_binary_crossentropy.value, optimizer=FeatureExtractorParam.optimizer_rmsprop.value)\n",
        "\n",
        "    return intermidiate_model\n",
        "\n",
        "class AnomalyDetectorParam(Enum):\n",
        "    activation_sigmoid = \"sigmoid\"\n",
        "    optimizer_rmsprop = 'rmsprop'\n",
        "\n",
        "# ANOMALY DETECTOR\n",
        "def anomaly_detector(g: Model, d: Model, e: Model, in_shape: tuple=(64,), loss_weights: list=[0.9, 0.1]) -> Model:\n",
        "    intermidiate_model = feature_extractor(d)\n",
        "    feature_extractor.trainable = False\n",
        "\n",
        "    g = Model(inputs=g.layers[1].input, outputs=g.layers[-1].output)\n",
        "    g.trainable = False\n",
        "    \n",
        "    a2Input = Input(shape=in_shape)\n",
        "\n",
        "    gInput = Dense(in_shape[0], trainable=True)(a2Input)\n",
        "    gInput = Activation(AnomalyDetectorParam.activation_sigmoid.value)(gInput)\n",
        "    \n",
        "    G_out = g(gInput)\n",
        "    D_out = intermidiate_model(G_out)\n",
        "    \n",
        "    model = Model(inputs=a2Input, outputs=[G_out, D_out])\n",
        "    model.compile(loss=sum_of_residual, loss_weights=loss_weights, optimizer=AnomalyDetectorParam.optimizer_rmsprop.value)\n",
        "    \n",
        "    K.set_learning_phase(0)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# COMPUTE THE ANOMALY SCORE OF THE QUERY USING THE ANOMALY DETECTOR,\n",
        "# WE ITERARE OVER Z IN ORDER TO FIND THE MOST SIMILAR IMAGE TO THE QUERY,\n",
        "# IN THE LAST ITERATION WE CAN COMPUTE THE LOSS \n",
        "def compute_anomaly_score(model: Model, x: np.array, iterations: int=500, d: Model=None, e: Model=None, noize_shape: tuple=(1, 64)) -> Tuple[np.asarray, np.asarray,]:\n",
        "    z = np.random.uniform(0, 1, size=noize_shape)\n",
        "    intermidiate_model = feature_extractor(d)\n",
        "    d_x = intermidiate_model.predict(x)\n",
        "    loss = model.fit(z, [x, d_x], batch_size=1, epochs=iterations, verbose=0)\n",
        "    similar_data, _ = model.predict(z)\n",
        "    loss = loss.history['loss'][-1]\n",
        "    \n",
        "    return loss, similar_data\n",
        "\n",
        "# GIVEN THE QUERY WE COMPUTE THE ANOMALY SCORE, WE FIND THE MOST SIMILAR IMAGE\n",
        "# AND WE PERFORM THE DIFFERENCE BETWEEN THE QUERY AND THE SIMILAR IMAGE \n",
        "def anomaly_detection(test_img: np.asarray, g: Model, d: Model, e: Model, iteration: int=200) -> Tuple[np.asarray, np.asarray, np.asarray, np.asarray,]:\n",
        "    model = anomaly_detector(g=g, d=d, e=e)\n",
        "    test_img_shape = test_img.shape\n",
        "    \n",
        "    ano_score, similar_img = compute_anomaly_score(model, test_img.reshape(1, test_img_shape[0], test_img_shape[1], test_img_shape[2]), iterations=iteration, d=d, e=e)\n",
        "    \n",
        "    np_residual = test_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) - similar_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2])\n",
        "    np_residual = (np_residual + 2) / 4\n",
        "    \n",
        "    np_residual = (255 * np_residual).astype(np.uint8)\n",
        "    #original_x = (test_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) * DataParm.image_size_127_5.value + DataParm.image_size_127_5.value).astype(np.uint8)\n",
        "    #similiar_x = (similar_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) * DataParm.image_size_127_5.value + DataParm.image_size_127_5.value).astype(np.uint8)\n",
        "    \n",
        "    #original_x_color = cv2.cvtColor(original_x, cv2.COLOR_GRAY2BGR)\n",
        "    #residual_color = cv2.applyColorMap(np_residual, cv2.COLORMAP_JET)\n",
        "    #show = cv2.addWeighted(original_x_color, 0.3, residual_color, 0.7, 0.)\n",
        "\n",
        "    sim = cv2.cvtColor(similar_img[0],cv2.COLOR_BGR2GRAY)\n",
        "    test = cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)\n",
        "    errors = np.abs(sim-test)\n",
        "    #errors = sim-test\n",
        "    #diff = np.mean(np.squeeze(errors),axis=2)\n",
        "    \n",
        "    return ano_score, test_img, similar_img[0], errors\n",
        "\n",
        "# BELOW WE HAVE A VARIATION OF THE CALCULATION OF THE ANOMALY SCORE,\n",
        "# NOW IS COMPUTED AS A MEAN OF MORE ANOMALY SCORE \n",
        "def anomaly_detector_second(g: Model, d: Model, in_shape: tuple=(64,), loss_weights: list=[0.9, 0.1]) -> Model:\n",
        "\n",
        "    intermidiate_model = feature_extractor(d)\n",
        "    feature_extractor.trainable = False\n",
        "\n",
        "    g = Model(inputs=g.layers[1].input, outputs=g.layers[-1].output)\n",
        "    g.trainable = False\n",
        "\n",
        "    aInput = Input(shape=in_shape)\n",
        "\n",
        "    gInput = Dense(in_shape[0], trainable=True)(aInput)\n",
        "    gInput = Activation(AnomalyDetectorParam.activation_sigmoid.value)(gInput)\n",
        "    \n",
        "    G_out = g(gInput)\n",
        "    D_out = intermidiate_model(G_out)\n",
        "\n",
        "    model = Model(inputs=aInput, outputs=[G_out, D_out])\n",
        "    model.compile(loss=sum_of_residual, loss_weights=loss_weights, optimizer=AnomalyDetectorParam.optimizer_rmsprop.value)\n",
        "    \n",
        "    K.set_learning_phase(0)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def compute_anomaly_score_second(model: Model, x: np.array, iterations: int=5, z_num: int=5, d: Model=None, g: Model=None, noize_shape: tuple=(1, 64)) -> Tuple[np.asarray, np.asarray,]:\n",
        "    loss_list = []\n",
        "    similar_data_list = []\n",
        "    initial_g = copy.deepcopy(g)\n",
        "    \n",
        "    for i in range(z_num):\n",
        "        z = np.random.uniform(0, 1, size=noize_shape)\n",
        "        intermidiate_model = feature_extractor(d)\n",
        "        d_x = intermidiate_model.predict(x)\n",
        "        loss = model.fit(z, [x, d_x], batch_size=1, epochs=iterations, verbose=0)\n",
        "        similar_data, _ = model.predict(z)\n",
        "        loss = loss.history['loss'][-1]\n",
        "        loss_list.append(loss)\n",
        "        similar_data_list.append(similar_data)\n",
        "        model = anomaly_detector_second(g=initial_g, d=d)\n",
        "      \n",
        "    average_loss = np.average(loss_list)\n",
        "    average_similar_data = np.average(similar_data_list, axis=0)\n",
        "    \n",
        "    return average_loss, average_similar_data\n",
        "\n",
        "def anomaly_detection_second(test_img, g=None, d=None, iterations: int=5) -> Tuple[np.asarray, np.asarray, np.asarray, np.asarray,]:\n",
        "    model = anomaly_detector_second(g=g, d=d)\n",
        "    test_img_shape = test_img.shape\n",
        "\n",
        "    ano_score, similar_img = compute_anomaly_score_second(model, test_img.reshape(1, test_img_shape[0], test_img_shape[1], test_img_shape[2]), iterations=iterations, d=d, g=g)\n",
        "    \n",
        "    np_residual = test_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) - similar_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2])\n",
        "    np_residual = (np_residual + 2) / 4\n",
        "    \n",
        "    np_residual = (255 * np_residual).astype(np.uint8)\n",
        "    sim = cv2.cvtColor(similar_img[0],cv2.COLOR_BGR2GRAY)\n",
        "    test = cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)\n",
        "    errors = np.abs(sim-test)\n",
        "    \n",
        "    return ano_score, test_img, similar_img[0], errors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxMuS6XBbCRr",
        "colab_type": "text"
      },
      "source": [
        "# Anomaly detectot using an **Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep8xKuSDBDqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mynoise(n):\n",
        "    return np.random.normal(0.0, 1.0, size = [n, 64])\n",
        "\n",
        "def sum_of_residual(y_true: np.array, y_pred: np.array):\n",
        "    return K.sum(K.abs(y_true - y_pred))\n",
        "\n",
        "class DataParm(Enum):\n",
        "    common_path = './model'\n",
        "    common_path_efficient = './model2'\n",
        "    image_size_127_5 = 127.5\n",
        "    batch_size_64 = 64\n",
        "\n",
        "class FeatureExtractorEncodeParam(Enum):\n",
        "    feature_extractor_loss = 'binary_crossentropy'\n",
        "    optimizer = 'adam'\n",
        "    \n",
        "class AnomalyDetectorEncodeParam(Enum):\n",
        "    adam = 'adam'\n",
        "\n",
        "def feature_extractor_encode(d: Model=None, common_path: str=\"Models\") -> Model:\n",
        "    input_layer = []\n",
        "\n",
        "    for index, each_d in enumerate(d.layers):\n",
        "        if 'input' in each_d.name:\n",
        "            input_layer.append(each_d.input)\n",
        "    \n",
        "    intermidiate_model = Model(inputs=input_layer, outputs=d.layers[-9].output)\n",
        "    intermidiate_model.compile(loss=FeatureExtractorEncodeParam.feature_extractor_loss.value, optimizer=FeatureExtractorEncodeParam.optimizer.value)\n",
        "\n",
        "    #plot_model(intermidiate_model, to_file=\"anomaly_detector_encoder.png\")\n",
        "    \n",
        "    return intermidiate_model\n",
        "\n",
        "def anomaly_detector_encode(g: Model, d: Model, e: Model, img_shape: tuple=(256, 256, 3), loss_weights: list=[0.9, 0.1]) -> Model:\n",
        "    intermidiate_model = feature_extractor_encode(d)\n",
        "    intermidiate_model.trainable = False\n",
        "    g = Model(inputs=g.layers[1].input, outputs=g.layers[-1].output)\n",
        "\n",
        "    g.trainable = False\n",
        "    e.trainable = False\n",
        "    \n",
        "    e = Model(inputs=e.layers[1].input, outputs=e.layers[-1].output)\n",
        "    aInput = Input(shape=img_shape)\n",
        "\n",
        "    E_out = e(aInput)\n",
        "    G_out = g(E_out)\n",
        "    D_out = intermidiate_model([G_out, E_out])\n",
        "\n",
        "    model = Model(inputs=aInput, outputs=[G_out, D_out])\n",
        "    model.compile(loss=sum_of_residual, loss_weights=loss_weights, optimizer=AnomalyDetectorEncodeParam.adam.value)\n",
        "    \n",
        "    K.set_learning_phase(0)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def l2_norm(x, y, axis=None):\n",
        "    if axis is None:\n",
        "        return tf.reduce_sum(tf.pow(x-y, 2))\n",
        "    else:\n",
        "        return tf.reduce_sum(tf.pow(x-y, 2), axis=axis)\n",
        "\n",
        "def MSE(x, y, axis=None):\n",
        "    if axis is None:\n",
        "        return tf.reduce_mean(tf.pow(x-y, 2))\n",
        "    else:\n",
        "        return tf.reduce_mean(tf.pow(x-y, 2), axis=axis)\n",
        "\n",
        "def compute_anomaly_score_encode(model: Model, intermidiate_model: Model, x: np.array, noise: np.array, d: Model=None, e: Model=None, g: Model=None) -> Tuple[np.asarray, np.asarray,]:\n",
        "    # LATENT REPRESENTATION OF THE TEST SAMPLE\n",
        "    generate_noise = e.predict(x)\n",
        "\n",
        "    # GENERATE IMAGE WITH LATENT REPRESENTATION OF SAMPLE TEST\n",
        "    generate_image = g.predict(generate_noise)\n",
        "    \n",
        "    # FEATURE REPRESENTATION OF GENERATED IMAGE AND TEST SAMPLE\n",
        "    target_d_x = intermidiate_model.predict([x, generate_noise])\n",
        "    d_x = intermidiate_model.predict([generate_image, noise])\n",
        "\n",
        "    # LATENT REPPRESENTATION OF THE GENERATED IMAGES\n",
        "    z_img_emb_query = e.predict(generate_image)\n",
        "\n",
        "    ####\n",
        "    #img_distance = tf.reduce_mean(l2_norm( x, generate_image, axis=1 ))   # distance based on images\n",
        "    #feature_distance = tf.reduce_mean(l2_norm( target_d_x, d_x, axis=1 ))   # distance based on images\n",
        "    #z_distance = tf.reduce_mean(l2_norm( generate_noise, z_img_emb_query, axis=1 ))  # distance based on z's\n",
        "    ####\n",
        "\n",
        "    ####\n",
        "    dual_iloss  = True\n",
        "    #loss_img = MSE( x, generate_image, axis=1 )\n",
        "\n",
        "    #if dual_iloss:\n",
        "    #    loss_fts = MSE( target_d_x, d_x, axis=1 )\n",
        "    #    img_distance2 = tf.reduce_mean(loss_img + 0.1*loss_fts)\n",
        "    #else:\n",
        "    #    img_distance2 = tf.reduce_mean(loss_img)\n",
        "\n",
        "    #z_distance = MSE( emb_query, z_img_emb_query, axis=1 )\n",
        "    ####\n",
        "\n",
        "    #loss = model.evaluate(generate_image, [x, target_d_x], batch_size=1, verbose=0)\n",
        "    #loss = loss[-1]\n",
        "\n",
        "    #loss = model.fit(generate_image, [x, target_d_x], epochs=200, batch_size=1, verbose=0)\n",
        "    #loss = loss.history['loss'][-1]\n",
        "    #similar_data, _ = model.predict(generate_image)\n",
        "\n",
        "\n",
        "    # COMPUTE THE DIFFERENCE PIXEL PER PIXEL BETWEEN\n",
        "    # THE QUERY AND THE GENERATED IMAGE\n",
        "    loss_image = [np.abs(each_x - g_x) for each_x, g_x in zip(x, generate_image)]\n",
        "    sum_loss_image = np.sum(loss_image)\n",
        "\n",
        "    # COMPUTE THE DIFFERENCE THE FEATURE REPRESENTATION \n",
        "    # OF THE QUERY AND OF THE GENERATED IMAGE\n",
        "    loss_feature = [np.abs(each_d_x - each_g_d_x) for each_d_x, each_g_d_x in zip(target_d_x, d_x)]\n",
        "    sum_loss_feature = np.sum(loss_feature)\n",
        "\n",
        "    loss_latent = [np.abs(each_d_x - each_g_d_x) for each_d_x, each_g_d_x in zip(generate_noise, z_img_emb_query)]\n",
        "    sum_loss_latent = np.sum(loss_latent)\n",
        "\n",
        "    #res_loss = tf.reduce_mean(tf.reduce_sum(tf.abs(tf.subtract(generate_image, x))))\n",
        "    #dis_loss = tf.reduce_mean(tf.reduce_sum(tf.abs(tf.subtract(target_d_x, d_x))))\n",
        "\n",
        "    # COMPUTE THE LOSS AS THE WEIGHTED SUM OF THE \n",
        "    # RESIDUAL LOSS AND THE DISCRIMINATOR LOSS\n",
        "    loss = 0.9*sum_loss_image + 0.1*sum_loss_feature + 0*sum_loss_latent\n",
        "\n",
        "    #with tf.Session() as sess:     \n",
        "        #loss = sess.run(loss)\n",
        "        #img_dist = sess.run(img_distance)\n",
        "        #z_dist = sess.run(z_distance)\n",
        "        #tmp = sess.run(img_distance2)\n",
        "    \n",
        "    return loss, generate_image\n",
        "\n",
        "def anomaly_detection_encode(test_img, noise, g=None, d=None, e=None, model=None, intermidiate_model=None) -> Tuple[np.asarray, np.asarray, np.asarray, np.asarray,]:\n",
        "    test_img_shape = test_img.shape\n",
        "\n",
        "    ano_score, similar_img = compute_anomaly_score_encode(model, intermidiate_model, test_img.reshape(1, test_img_shape[0], test_img_shape[1], test_img_shape[2]), noise, d=d, e=e, g=g)\n",
        "\n",
        "    np_residual = test_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) - similar_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2])\n",
        "    np_residual = (np_residual + 2) / 4\n",
        "    \n",
        "    np_residual = (255 * np_residual).astype(np.uint8)\n",
        "    #original_x = (test_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) * DataParm.image_size_127_5.value + DataParm.image_size_127_5.value).astype(np.uint8)\n",
        "    #similiar_x = (similar_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]) * DataParm.image_size_127_5.value + DataParm.image_size_127_5.value).astype(np.uint8)\n",
        "    #original_x = (test_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]))\n",
        "    #similiar_x = (similar_img.reshape(test_img_shape[0], test_img_shape[1], test_img_shape[2]))\n",
        "\n",
        "    #original_x_color = cv2.cvtColor(original_x, cv2.COLOR_RGB2BGR)\n",
        "    #residual_color = cv2.applyColorMap(np_residual, cv2.COLORMAP_JET)\n",
        "    #show = cv2.addWeighted(original_x_color, 0.3, residual_color, 0.7, 0.)\n",
        "\n",
        "    sim = cv2.cvtColor(similar_img[0],cv2.COLOR_BGR2GRAY)\n",
        "    test = cv2.cvtColor(test_img,cv2.COLOR_BGR2GRAY)\n",
        "    errors = np.abs(sim-test)\n",
        "    #errors = sim-test\n",
        "    #diff = np.mean(np.squeeze(errors),axis=2)\n",
        "    \n",
        "    return ano_score, test_img, similar_img[0], errors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF59TH7mbJDy",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_grxsT7UPg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = e.predict(X_test[:len(X_test)-1])\n",
        "img = g.predict(nn)\n",
        "plt.imshow(img[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw-AxqOa3RUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadModel(name, num, object_name):\n",
        "    #CABLE: 12\n",
        "    #Toothbrush: 4\n",
        "    #Screw: 100\n",
        "\n",
        "    file = open(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+object_name+\"/\"+name+\".json\", 'r')\n",
        "    json = file.read()\n",
        "    file.close()\n",
        "\n",
        "    mod = model_from_json(json)\n",
        "    mod.load_weights(\"/content/drive/My Drive/Colab Notebooks/BiGAN/\"+object_name+\"/\"+name+\"_\"+str(num)+\".h5\")\n",
        "\n",
        "    return mod\n",
        "\n",
        "def get_test_data(DATASET_TRAIN_PATH, im_size):\n",
        "  #DATASET_TRAIN_PATH = \"/content/drive/My Drive/Colab Notebooks/test_AD_1/\"+object_name+\"/test/broken_small\"\n",
        "  X_test = []\n",
        "  cmode = \"RGB\"\n",
        "  size_adjusted = False\n",
        "\n",
        "  for dirpath, dirnames, filenames in os.walk(DATASET_TRAIN_PATH):\n",
        "      for filename in [f for f in filenames if f.endswith(\".\"+str('png'))]:\n",
        "          print('\\r' + str(len(X_test)), end = '\\r')\n",
        "          \n",
        "          fname = os.path.join(dirpath, filename)\n",
        "\n",
        "          temp = Image.open(fname).convert(cmode)\n",
        "          if not size_adjusted:\n",
        "              temp = temp.resize((im_size, im_size), Image.BILINEAR)\n",
        "\n",
        "          temp = np.array(temp, dtype='uint8')\n",
        "          X_test.append(temp)\n",
        "\n",
        "  X_test = np.array(X_test)\n",
        "  X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "  return X_test\n",
        "\n",
        "# LOAD THE DATASET\n",
        "#object_name = \"Bottle\"\n",
        "#X_test = get_test_data(lower(object_name))\n",
        "\n",
        "# LOAD THE PRETRAINED MODEL\n",
        "#num = 22\n",
        "#g = loadModel(\"gen\", num, object_name)\n",
        "#d = loadModel(\"dis\", num, object_name)\n",
        "#e = loadModel(\"enc\", num, object_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmV2NwrIQgA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE A DICTONARY THAT CONTAIN FOR EACH OBJECT THE TEST SAMPLE\n",
        "# WE HAVE 2 DIFFERENT DICTONARY TO MANTAIN THE IMAGE IN 128X128 AND 256X256\n",
        "dataset_256 = {}\n",
        "dataset_128 = {}\n",
        "for object_name in os.listdir(\"/content/drive/My Drive/Colab Notebooks/test_AD_1/\"):\n",
        "  print(\"\\n\\n#  ACTUAL OBJECT: {} #\".format(object_name))\n",
        "  dataset_128[object_name] = {}\n",
        "  dataset_256[object_name] = {}\n",
        "  for dirnames in os.listdir(\"/content/drive/My Drive/Colab Notebooks/test_AD_1/\"+object_name+\"/\"):\n",
        "    try:\n",
        "      if(dirnames != \"ground_truth\" and dirnames != \"train\" and dirnames != \"license.txt\" and dirnames != \"readme.txt\"):\n",
        "        print(\"\\n\\t###  ACTUAL DIRECTORY: {} ###\".format(dirnames))\n",
        "        dataset_128[object_name][dirnames] = {}\n",
        "        dataset_256[object_name][dirnames] = {}\n",
        "        for sub_dirnames in os.listdir(os.path.join(\"/content/drive/My Drive/Colab Notebooks/test_AD_1/\"+object_name+\"/\", dirnames)):\n",
        "          dir_path = os.path.join(\"/content/drive/My Drive/Colab Notebooks/test_AD_1/\"+object_name+\"/\", dirnames, sub_dirnames)\n",
        "          print(\"\\t\\t\" + dir_path)\n",
        "          X_test_128 = get_test_data(dir_path, 128)\n",
        "          X_test_256 = get_test_data(dir_path, 256)\n",
        "          dataset_128[object_name][dirnames][sub_dirnames] =  X_test_128\n",
        "          dataset_256[object_name][dirnames][sub_dirnames] =  X_test_256\n",
        "    except Exception as e:\n",
        "      pass\n",
        "      #print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKS19AHxqeWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save\n",
        "#np.save('/content/drive/My Drive/Colab Notebooks/mvtec_dataset/my_dataset_256.npy', dataset_256) \n",
        "#np.save('/content/drive/My Drive/Colab Notebooks/mvtec_dataset/my_dataset_128.npy', dataset_128) \n",
        "\n",
        "# Load\n",
        "dataset_256 = np.load('/content/drive/My Drive/Colab Notebooks/mvtec_dataset/my_dataset_256.npy', allow_pickle='TRUE').item()\n",
        "dataset_128 = np.load('/content/drive/My Drive/Colab Notebooks/mvtec_dataset/my_dataset_128.npy', allow_pickle='TRUE').item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ZekkvbrGBy",
        "colab_type": "text"
      },
      "source": [
        "Feature representation of the normla and anomaly object using the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhwk7p95w-1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_map_good = []\n",
        "feature_map_anomaly = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ5OexvNpO-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = feature_extractor_encode(d)\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "for query in X_test:  \n",
        "  query_img_shape = query.shape\n",
        "  query = query.reshape(1, query_img_shape[0], query_img_shape[1], query_img_shape[2])\n",
        "  generate_noise = e.predict(query)\n",
        "  if \"good\" in DATASET_TRAIN_PATH:\n",
        "    feature_map_good.append(model.predict([query, generate_noise]))\n",
        "  else:\n",
        "    feature_map_anomaly.append(model.predict([query, generate_noise]))\n",
        "\n",
        "if len(feature_map_good) > 0 and len(feature_map_anomaly) > 0:\n",
        "  np_feature_map_good = np.array(feature_map_good)\n",
        "  np_feature_map_anomaly = np.array(feature_map_anomaly)\n",
        "\n",
        "  output = np.concatenate((np_feature_map_good, np_feature_map_anomaly))\n",
        "  output = output.reshape(output.shape[0], -1)\n",
        "\n",
        "  X_embedded = TSNE(n_components = 2).fit_transform(output)\n",
        "  plt.figure(5)\n",
        "  plt.title(\"T-SNE embedding on the feature representation\")\n",
        "  plt.scatter(X_embedded[:len(feature_map_good), 0], X_embedded[:len(feature_map_good), 1], label='normal')\n",
        "  plt.scatter(X_embedded[len(feature_map_good):, 0], X_embedded[len(feature_map_good):, 1], label='anomaly')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf7vl8rLrQ0o",
        "colab_type": "text"
      },
      "source": [
        "Testing the anomaly detector "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjDnJYnE4Beu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_list = []\n",
        "Y_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V82767W2g2ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 12\n",
        "object_name = \"Transistor\"\n",
        "g = loadModel(\"gen\", num, object_name)\n",
        "d = loadModel(\"dis\", num, object_name)\n",
        "e = loadModel(\"enc\", num, object_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFvgDKDCJcMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = True\n",
        "\n",
        "object_list = [\"screw\"]\n",
        "\n",
        "for o in object_list:\n",
        "\n",
        "  num = 100\n",
        "  object_name = o.capitalize()\n",
        "  g = loadModel(\"gen\", num, object_name)\n",
        "  d = loadModel(\"dis\", num, object_name)\n",
        "  e = loadModel(\"enc\", num, object_name)\n",
        "\n",
        "  type_of_anomalies = []\n",
        "  for elem in dataset_256[o][\"test\"]:\n",
        "    print(elem)\n",
        "    type_of_anomalies.append(elem)\n",
        "\n",
        "  dim = 128\n",
        "  flag = False\n",
        "  for i in range(0,len(type_of_anomalies)):\n",
        "    \n",
        "    try:\n",
        "      if dim == 128:\n",
        "        dataset = dataset_128\n",
        "      else:\n",
        "        dataset = dataset_256\n",
        "\n",
        "      if encoder:\n",
        "        model = anomaly_detector_encode(g=g, d=d, e=e, img_shape=(dim,dim,3))\n",
        "        intermidiate_model = feature_extractor_encode(d)\n",
        "\n",
        "      if flag:\n",
        "        flag = False\n",
        "        i -= 1\n",
        "      \n",
        "      for elem in dataset[o][\"test\"][type_of_anomalies[i]]:\n",
        "        if type_of_anomalies[i] == \"good\":\n",
        "          y_true = 0\n",
        "        else:\n",
        "          y_true = 1\n",
        "        \n",
        "        n1 = mynoise(1)\n",
        "\n",
        "        start = cv2.getTickCount()\n",
        "\n",
        "        if encoder:\n",
        "          score, query, pred, diff= anomaly_detection_encode(elem, n1, g=g, d=d, e=e, model=model, intermidiate_model=intermidiate_model)\n",
        "        else:\n",
        "          score, query, pred, diff = anomaly_detection(elem, g=g, d=d, e=e, iteration=500)\n",
        "          #score, query, pred, diff = anomaly_detection_second(elem, g=g, d=d, iterations=30,)\n",
        "\n",
        "        time = (cv2.getTickCount() - start) / cv2.getTickFrequency() * 100\n",
        "        \n",
        "        f, axarr = plt.subplots(1,3)\n",
        "\n",
        "        axarr[0].imshow(query)\n",
        "        axarr[0].axis(\"off\")\n",
        "        axarr[0].title.set_text(\"Query\")\n",
        "\n",
        "        axarr[1].imshow(pred)\n",
        "        axarr[1].axis(\"off\")\n",
        "        axarr[1].title.set_text(\"Generated\")\n",
        "\n",
        "        axarr[2].imshow(diff)\n",
        "        axarr[2].axis(\"off\")\n",
        "        axarr[2].title.set_text(\"Difference\")\n",
        "\n",
        "        title = type_of_anomalies[i].upper() + \" - ANOMALY SCORE: {} IN {} ms\".format(round(score, 2), round(time, 2))\n",
        "\n",
        "        plt.suptitle(title, fontsize=12, x = 0.5, y = 0.8)\n",
        "\n",
        "        plt.show()\n",
        "        \n",
        "        score_list.append(score)\n",
        "        Y_list.append(y_true)\n",
        "    except Exception as exc:\n",
        "      print(exc)\n",
        "\n",
        "      if dim == 128:\n",
        "        dim = 256\n",
        "      else:\n",
        "        if dim == 256:\n",
        "          dim = 128\n",
        "      \n",
        "      flag = True\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wokyrOCoOsZx",
        "colab_type": "text"
      },
      "source": [
        "Plot the distribution of the anomaly and normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZb3uZr7K3ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(color_codes=False)\n",
        "\n",
        "y = score_list\n",
        "#sns.kdeplot(x, shade=True, color=\"m\", label=\"normal\")\n",
        "sns.kdeplot(y, shade=True, color=\"r\", label=\"anomaly\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEOVya6YOj7R",
        "colab_type": "text"
      },
      "source": [
        "Normalize the anomaly score in range 0,1 and compute the error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eknJUzawBv6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_score_list = (score_list-np.min(score_list))/(np.max(score_list)-np.min(score_list))\n",
        "print(norm_score_list)\n",
        "y_predict = []\n",
        "\n",
        "for elem in norm_score_list:\n",
        "  if elem > 0.5:\n",
        "    y_predict.append(1)\n",
        "  else:\n",
        "    y_predict.append(0)\n",
        "\n",
        "error = 0\n",
        "i = 0\n",
        "for elem in y_predict:\n",
        "  \n",
        "  if elem != Y_list[i]:\n",
        "    error += 1 \n",
        "\n",
        "  i+=1\n",
        "\n",
        "error = error/len(y_predict)\n",
        "print(error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li1hB0idOegf",
        "colab_type": "text"
      },
      "source": [
        "Plot ROC curve "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM5lpj544YVQ",
        "colab_type": "code",
        "outputId": "47c0d993-6428-4936-f89e-e07a09e382c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# False Positive Rateã€True Positive Rate\n",
        "fpr, tpr, threshold = roc_curve(Y_list, score_list)\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='red', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='m', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjQ95L1gtq-m",
        "colab_type": "text"
      },
      "source": [
        "# Other method to compute anomaly score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcn-YU088ZQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.measure import compare_ssim\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "# 3. Load the two input images\n",
        "for elem in X_test:\n",
        "  imageA = elem\n",
        "  temp = []\n",
        "  temp.append(imageA)\n",
        "  gen_noise = e.predict(np.array(temp))\n",
        "  gen_img = g.predict(gen_noise)\n",
        "  imageB = gen_img[0]\n",
        "\n",
        "  # 4. Convert the images to grayscale\n",
        "  grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
        "  grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # 5. Compute the Structural Similarity Index (SSIM) between the two\n",
        "  #    images, ensuring that the difference image is returned\n",
        "  (score, diff) = compare_ssim(grayA, grayB, full=True)\n",
        "  diff = (diff * 255).astype(\"uint8\")\n",
        "\n",
        "  plt.imshow(diff)\n",
        "  plt.show()\n",
        "\n",
        "  # 6. You can print only the score if you want\n",
        "  print(\"SSIM: {}\".format(score))\n",
        "\n",
        "  score_list.append(score)\n",
        "  Y_list.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PubkOT-_-gpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from scipy import signal\n",
        "from scipy import ndimage\n",
        "\n",
        "def gaussian2(size, sigma):\n",
        "  \"\"\"Returns a normalized circularly symmetric 2D gauss kernel array\n",
        "\n",
        "  f(x,y) = A.e^{-(x^2/2*sigma^2 + y^2/2*sigma^2)} where\n",
        "\n",
        "  A = 1/(2*pi*sigma^2)\n",
        "\n",
        "  as define by Wolfram Mathworld \n",
        "  http://mathworld.wolfram.com/GaussianFunction.html\n",
        "  \"\"\"\n",
        "  A = 1/(2.0*numpy.pi*sigma**2)\n",
        "  x, y = numpy.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "  g = A*numpy.exp(-((x**2/(2.0*sigma**2))+(y**2/(2.0*sigma**2))))\n",
        "  return g\n",
        "\n",
        "def fspecial_gauss(size, sigma):\n",
        "  \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "  \"\"\"\n",
        "  x, y = numpy.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "  g = numpy.exp(-((x**2 + y**2)/(2.0*sigma**2)))\n",
        "  return g/g.sum()\n",
        "\n",
        "def msssim(img1, img2):\n",
        "  \"\"\"This function implements Multi-Scale Structural Similarity (MSSSIM) Image \n",
        "  Quality Assessment according to Z. Wang's \"Multi-scale structural similarity \n",
        "  for image quality assessment\" Invited Paper, IEEE Asilomar Conference on \n",
        "  Signals, Systems and Computers, Nov. 2003 \n",
        "  \n",
        "  Author's MATLAB implementation:-\n",
        "  http://www.cns.nyu.edu/~lcv/ssim/msssim.zip\n",
        "  \"\"\"\n",
        "  level = 5\n",
        "  weight = numpy.array([0.0448, 0.2856, 0.3001, 0.2363, 0.1333])\n",
        "  downsample_filter = numpy.ones((2, 2))/4.0\n",
        "  im1 = img1.astype(numpy.float64)\n",
        "  im2 = img2.astype(numpy.float64)\n",
        "  mssim = numpy.array([])\n",
        "  mcs = numpy.array([])\n",
        "  for l in range(level):\n",
        "      ssim_map, cs_map = ssim(im1, im2, cs_map=True)\n",
        "      mssim = numpy.append(mssim, ssim_map.mean())\n",
        "      mcs = numpy.append(mcs, cs_map.mean())\n",
        "      filtered_im1 = ndimage.filters.convolve(im1, downsample_filter, \n",
        "                                              mode='reflect')\n",
        "      filtered_im2 = ndimage.filters.convolve(im2, downsample_filter, \n",
        "                                              mode='reflect')\n",
        "      im1 = filtered_im1[::2, ::2]\n",
        "      im2 = filtered_im2[::2, ::2]\n",
        "  return (numpy.prod(mcs[0:level-1]**weight[0:level-1])*\n",
        "                  (mssim[level-1]**weight[level-1]))\n",
        "\n",
        "def ssim(img1, img2, cs_map=False):\n",
        "  print(img1.shape)\n",
        "  print(img2.shape)\n",
        "  \"\"\"Return the Structural Similarity Map corresponding to input images img1 \n",
        "  and img2 (images are assumed to be uint8)\n",
        "\n",
        "  This function attempts to mimic precisely the functionality of ssim.m a \n",
        "  MATLAB provided by the author's of SSIM\n",
        "  https://ece.uwaterloo.ca/~z70wang/research/ssim/ssim_index.m\n",
        "  \"\"\"\n",
        "  img1 = img1.astype(numpy.float64)\n",
        "  img2 = img2.astype(numpy.float64)\n",
        "  size = 11\n",
        "  sigma = 1.5\n",
        "  window = fspecial_gauss(size, sigma)\n",
        "  K1 = 0.01\n",
        "  K2 = 0.03\n",
        "  L = 255 #bitdepth of image\n",
        "  C1 = (K1*L)**2\n",
        "  C2 = (K2*L)**2\n",
        "  print(window.shape)\n",
        "  mu1 = signal.fftconvolve(window, img1, mode='valid')\n",
        "  mu2 = signal.fftconvolve(window, img2, mode='valid')\n",
        "  mu1_sq = mu1*mu1\n",
        "  mu2_sq = mu2*mu2\n",
        "  mu1_mu2 = mu1*mu2\n",
        "  sigma1_sq = signal.fftconvolve(window, img1*img1, mode='valid') - mu1_sq\n",
        "  sigma2_sq = signal.fftconvolve(window, img2*img2, mode='valid') - mu2_sq\n",
        "  sigma12 = signal.fftconvolve(window, img1*img2, mode='valid') - mu1_mu2\n",
        "  if cs_map:\n",
        "      return (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                  (sigma1_sq + sigma2_sq + C2)), \n",
        "              (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
        "  else:\n",
        "      return ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                  (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "imageA = X_test[6]\n",
        "temp = []\n",
        "temp.append(imageA)\n",
        "gen_noise = e.predict(np.array(temp))\n",
        "gen_img = g.predict(gen_noise)\n",
        "imageB = gen_img[0]\n",
        "\n",
        "imageA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
        "imageB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "image1 = numpy.array(imageA)\n",
        "image2 = numpy.array(imageB)\n",
        "\n",
        "ssim_map = ssim(image1, image2)\n",
        "ms_ssim = msssim(image1, image2)\n",
        "\n",
        "import pylab\n",
        "\n",
        "pylab.figure()\n",
        "pylab.subplot(131)\n",
        "pylab.title('Image1')\n",
        "pylab.imshow(imageA, interpolation='nearest', cmap=pylab.gray())\n",
        "pylab.subplot(132)\n",
        "pylab.title('Image2')\n",
        "pylab.imshow(imageB, interpolation='nearest', cmap=pylab.gray())\n",
        "pylab.subplot(133)\n",
        "pylab.title('SSIM Map\\n SSIM: %f\\n MSSSIM: %f' % (ssim_map.mean(), ms_ssim))\n",
        "pylab.imshow(ssim_map, interpolation='nearest', cmap=pylab.gray())\n",
        "pylab.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91-plvVW_c4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def log10(x):\n",
        "    numerator = tf.log(x)\n",
        "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
        "    return numerator / denominator\n",
        "\n",
        "\n",
        "def psnr(im1, im2):\n",
        "    img_arr1 = numpy.array(im1).astype('float32')\n",
        "    img_arr2 = numpy.array(im2).astype('float32')\n",
        "    mse = tf.reduce_mean(tf.squared_difference(img_arr1, img_arr2))\n",
        "    psnr = tf.constant(255**2, dtype=tf.float32)/mse\n",
        "    result = tf.constant(10, dtype=tf.float32)*log10(psnr)\n",
        "    with tf.Session():\n",
        "        result = result.eval()\n",
        "    return result\n",
        "\n",
        "imageA = X_test[4]\n",
        "temp = []\n",
        "temp.append(imageA)\n",
        "gen_noise = e.predict(np.array(temp))\n",
        "gen_img = g.predict(gen_noise)\n",
        "imageB = gen_img[0]\n",
        "\n",
        "psnr(imageA, imageB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3edkW3lE1DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python -v"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}